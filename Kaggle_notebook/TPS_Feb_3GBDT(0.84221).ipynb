{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":868},"executionInfo":{"elapsed":18394,"status":"ok","timestamp":1614082416910,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"PqDjp0dFX5Sq","outputId":"0d5ba3a7-1588-4a6d-b3f9-3c66d8cc6323"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Uninstalling lightgbm-3.1.1:\n","  Would remove:\n","    /usr/local/lib/python3.6/dist-packages/lightgbm-3.1.1.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/lightgbm/*\n","Proceed (y/n)? y\n","  Successfully uninstalled lightgbm-3.1.1\n","Collecting lightgbm\n","  Using cached https://files.pythonhosted.org/packages/70/cd/2b7783e8c250f8191b72e9a0010e0429a799d3305c27764d7bf113dfd078/lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.36.2)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn!=0.22.0-\u003elightgbm) (1.0.0)\n","Installing collected packages: lightgbm\n","Successfully installed lightgbm-3.1.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["lightgbm"]}}},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting catboost\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n","\u001b[K     |████████████████████████████████| 65.8MB 97kB/s \n","\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: numpy\u003e=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: pandas\u003e=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: retrying\u003e=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly-\u003ecatboost) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib-\u003ecatboost) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-\u003ecatboost) (2.4.7)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-\u003ecatboost) (2.8.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-\u003ecatboost) (1.3.1)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas\u003e=0.24.0-\u003ecatboost) (2018.9)\n","Installing collected packages: catboost\n","Successfully installed catboost-0.24.4\n","Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n","Requirement already satisfied: pandas\u003e=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n","Requirement already satisfied: patsy\u003e=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.5)\n","Requirement already satisfied: scipy\u003e=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: scikit-learn\u003e=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied: statsmodels\u003e=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas\u003e=0.21.1-\u003ecategory_encoders) (2.8.1)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas\u003e=0.21.1-\u003ecategory_encoders) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy\u003e=0.5.1-\u003ecategory_encoders) (1.15.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn\u003e=0.20.0-\u003ecategory_encoders) (1.0.0)\n"]}],"source":["# !git clone --recursive https://github.com/Microsoft/LightGBM\r\n","# ! cd LightGBM \u0026\u0026 rm -rf build \u0026\u0026 mkdir build \u0026\u0026 cd build \u0026\u0026 cmake -DUSE_GPU=1 ../../LightGBM \u0026\u0026 make -j4 \u0026\u0026 cd ../python-package \u0026\u0026 python3 setup.py install --precompile --gpu;\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","\r\n","!pip uninstall lightgbm\r\n","!pip install lightgbm\r\n","\r\n","import os\r\n","import sys\r\n","import time\r\n","import random\r\n","import logging\r\n","import typing as tp\r\n","from pathlib import Path\r\n","from contextlib import contextmanager\r\n","\r\n","from matplotlib import pyplot as plt\r\n","import seaborn as sns\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","!pip install catboost\r\n","!pip install category_encoders\r\n","import category_encoders as ce\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.metrics import mean_squared_log_error, mean_squared_error\r\n","\r\n","import xgboost as xgb\r\n","import lightgbm as lgb\r\n","from catboost import CatBoost, Pool\r\n","\r\n","%matplotlib inline"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3395,"status":"ok","timestamp":1614082574856,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"XGkxXya0YJM4"},"outputs":[],"source":["path = '/content/drive/Shareddrives/dacon/Playground/'\r\n","train = pd.read_csv(path + 'train.csv')\r\n","test = pd.read_csv(path + 'test.csv')\r\n","smpl_sub = pd.read_csv(path + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"executionInfo":{"elapsed":875,"status":"ok","timestamp":1614082448264,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"WB7xw6gJYXM6","outputId":"7b6b434e-8615-4b77-bde8-ca48422c0a9a"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003cth\u003e6\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat0\u003c/th\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat1\u003c/th\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat2\u003c/th\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat3\u003c/th\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat4\u003c/th\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat5\u003c/th\u003e\n","      \u003ctd\u003eD\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eD\u003c/td\u003e\n","      \u003ctd\u003eD\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat6\u003c/th\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat7\u003c/th\u003e\n","      \u003ctd\u003eE\u003c/td\u003e\n","      \u003ctd\u003eE\u003c/td\u003e\n","      \u003ctd\u003eB\u003c/td\u003e\n","      \u003ctd\u003eE\u003c/td\u003e\n","      \u003ctd\u003eE\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat8\u003c/th\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eG\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat9\u003c/th\u003e\n","      \u003ctd\u003eI\u003c/td\u003e\n","      \u003ctd\u003eF\u003c/td\u003e\n","      \u003ctd\u003eN\u003c/td\u003e\n","      \u003ctd\u003eK\u003c/td\u003e\n","      \u003ctd\u003eF\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt0\u003c/th\u003e\n","      \u003ctd\u003e0.923191\u003c/td\u003e\n","      \u003ctd\u003e0.437627\u003c/td\u003e\n","      \u003ctd\u003e0.732209\u003c/td\u003e\n","      \u003ctd\u003e0.705142\u003c/td\u003e\n","      \u003ctd\u003e0.486063\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt1\u003c/th\u003e\n","      \u003ctd\u003e0.684968\u003c/td\u003e\n","      \u003ctd\u003e0.014213\u003c/td\u003e\n","      \u003ctd\u003e0.760122\u003c/td\u003e\n","      \u003ctd\u003e0.771678\u003c/td\u003e\n","      \u003ctd\u003e0.639349\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt2\u003c/th\u003e\n","      \u003ctd\u003e0.124454\u003c/td\u003e\n","      \u003ctd\u003e0.357438\u003c/td\u003e\n","      \u003ctd\u003e0.454644\u003c/td\u003e\n","      \u003ctd\u003e0.153735\u003c/td\u003e\n","      \u003ctd\u003e0.496212\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt3\u003c/th\u003e\n","      \u003ctd\u003e0.217886\u003c/td\u003e\n","      \u003ctd\u003e0.846127\u003c/td\u003e\n","      \u003ctd\u003e0.81299\u003c/td\u003e\n","      \u003ctd\u003e0.732893\u003c/td\u003e\n","      \u003ctd\u003e0.354186\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt4\u003c/th\u003e\n","      \u003ctd\u003e0.281421\u003c/td\u003e\n","      \u003ctd\u003e0.282354\u003c/td\u003e\n","      \u003ctd\u003e0.293756\u003c/td\u003e\n","      \u003ctd\u003e0.769785\u003c/td\u003e\n","      \u003ctd\u003e0.279105\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt5\u003c/th\u003e\n","      \u003ctd\u003e0.881122\u003c/td\u003e\n","      \u003ctd\u003e0.440011\u003c/td\u003e\n","      \u003ctd\u003e0.914155\u003c/td\u003e\n","      \u003ctd\u003e0.934138\u003c/td\u003e\n","      \u003ctd\u003e0.3826\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt6\u003c/th\u003e\n","      \u003ctd\u003e0.42165\u003c/td\u003e\n","      \u003ctd\u003e0.34623\u003c/td\u003e\n","      \u003ctd\u003e0.369602\u003c/td\u003e\n","      \u003ctd\u003e0.57893\u003c/td\u003e\n","      \u003ctd\u003e0.70594\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt7\u003c/th\u003e\n","      \u003ctd\u003e0.741413\u003c/td\u003e\n","      \u003ctd\u003e0.278495\u003c/td\u003e\n","      \u003ctd\u003e0.832564\u003c/td\u003e\n","      \u003ctd\u003e0.407313\u003c/td\u003e\n","      \u003ctd\u003e0.325193\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt8\u003c/th\u003e\n","      \u003ctd\u003e0.895799\u003c/td\u003e\n","      \u003ctd\u003e0.593413\u003c/td\u003e\n","      \u003ctd\u003e0.86562\u003c/td\u003e\n","      \u003ctd\u003e0.868099\u003c/td\u003e\n","      \u003ctd\u003e0.440967\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt9\u003c/th\u003e\n","      \u003ctd\u003e0.802461\u003c/td\u003e\n","      \u003ctd\u003e0.546056\u003c/td\u003e\n","      \u003ctd\u003e0.825251\u003c/td\u003e\n","      \u003ctd\u003e0.794402\u003c/td\u003e\n","      \u003ctd\u003e0.462146\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt10\u003c/th\u003e\n","      \u003ctd\u003e0.724417\u003c/td\u003e\n","      \u003ctd\u003e0.613252\u003c/td\u003e\n","      \u003ctd\u003e0.264104\u003c/td\u003e\n","      \u003ctd\u003e0.494269\u003c/td\u003e\n","      \u003ctd\u003e0.724447\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt11\u003c/th\u003e\n","      \u003ctd\u003e0.701915\u003c/td\u003e\n","      \u003ctd\u003e0.741289\u003c/td\u003e\n","      \u003ctd\u003e0.695561\u003c/td\u003e\n","      \u003ctd\u003e0.698125\u003c/td\u003e\n","      \u003ctd\u003e0.683073\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt12\u003c/th\u003e\n","      \u003ctd\u003e0.877618\u003c/td\u003e\n","      \u003ctd\u003e0.326679\u003c/td\u003e\n","      \u003ctd\u003e0.869133\u003c/td\u003e\n","      \u003ctd\u003e0.809799\u003c/td\u003e\n","      \u003ctd\u003e0.343457\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt13\u003c/th\u003e\n","      \u003ctd\u003e0.719903\u003c/td\u003e\n","      \u003ctd\u003e0.808464\u003c/td\u003e\n","      \u003ctd\u003e0.828352\u003c/td\u003e\n","      \u003ctd\u003e0.614766\u003c/td\u003e\n","      \u003ctd\u003e0.297743\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003ctd\u003e6.99402\u003c/td\u003e\n","      \u003ctd\u003e8.07126\u003c/td\u003e\n","      \u003ctd\u003e5.76046\u003c/td\u003e\n","      \u003ctd\u003e7.80646\u003c/td\u003e\n","      \u003ctd\u003e6.86897\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["id             1         2         3         4         6\n","cat0           A         B         A         A         A\n","cat1           B         A         A         A         B\n","cat2           A         A         A         A         A\n","cat3           A         A         C         C         A\n","cat4           B         B         B         B         B\n","cat5           D         B         D         D         B\n","cat6           A         A         A         A         A\n","cat7           E         E         B         E         E\n","cat8           C         A         C         G         C\n","cat9           I         F         N         K         F\n","cont0   0.923191  0.437627  0.732209  0.705142  0.486063\n","cont1   0.684968  0.014213  0.760122  0.771678  0.639349\n","cont2   0.124454  0.357438  0.454644  0.153735  0.496212\n","cont3   0.217886  0.846127   0.81299  0.732893  0.354186\n","cont4   0.281421  0.282354  0.293756  0.769785  0.279105\n","cont5   0.881122  0.440011  0.914155  0.934138    0.3826\n","cont6    0.42165   0.34623  0.369602   0.57893   0.70594\n","cont7   0.741413  0.278495  0.832564  0.407313  0.325193\n","cont8   0.895799  0.593413   0.86562  0.868099  0.440967\n","cont9   0.802461  0.546056  0.825251  0.794402  0.462146\n","cont10  0.724417  0.613252  0.264104  0.494269  0.724447\n","cont11  0.701915  0.741289  0.695561  0.698125  0.683073\n","cont12  0.877618  0.326679  0.869133  0.809799  0.343457\n","cont13  0.719903  0.808464  0.828352  0.614766  0.297743\n","target   6.99402   8.07126   5.76046   7.80646   6.86897"]},"execution_count":5,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["train.head().T"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":854,"status":"ok","timestamp":1614082923482,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"xzv8plJJ6zyX"},"outputs":[],"source":["@contextmanager\r\n","def timer(logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None):\r\n","    if prefix: format_str = str(prefix) + format_str\r\n","    if suffix: format_str = format_str + str(suffix)\r\n","    start = time.time()\r\n","    yield\r\n","    d = time.time() - start\r\n","    out_str = format_str.format(d)\r\n","    if logger:\r\n","        logger.info(out_str)\r\n","    else:\r\n","        print(out_str)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1476,"status":"ok","timestamp":1614082484332,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"m2_U1Sdn7K2S"},"outputs":[],"source":["def rmse(y_true, y_pred):\r\n","    return np.sqrt(np.mean((y_true - y_pred) ** 2))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1376,"status":"ok","timestamp":1614082518267,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"c186AL_z7pT7"},"outputs":[],"source":["class TreeModel:\r\n","    \"\"\"Wrapper for LightGBM/XGBoost/CATBoost\"\"\"\r\n","    def __init__(self, model_type: str):\r\n","        self.model_type = model_type\r\n","        self.trn_data = None\r\n","        self.val_data = None\r\n","        self.model = None\r\n","\r\n","    def train(self,\r\n","              params: dict,\r\n","              X_train: pd.DataFrame, y_train: np.ndarray,\r\n","              X_val: pd.DataFrame, y_val: np.ndarray,\r\n","              train_weight: tp.Optional[np.ndarray] = None,\r\n","              val_weight: tp.Optional[np.ndarray] = None,\r\n","              train_params: dict = None,\r\n","              cat_cols: list = None,\r\n","            ):\r\n","        if self.model_type == \"lgb\":\r\n","            self.trn_data = lgb.Dataset(X_train, label=y_train, weight=train_weight)\r\n","            self.val_data = lgb.Dataset(X_val, label=y_val, weight=val_weight)\r\n","            self.model = lgb.train(params=params,\r\n","                                   train_set=self.trn_data,\r\n","                                   valid_sets=[self.trn_data, self.val_data],\r\n","                                   **train_params)\r\n","        elif self.model_type == \"xgb\":\r\n","            self.trn_data = xgb.DMatrix(X_train, y_train, weight=train_weight)\r\n","            self.val_data = xgb.DMatrix(X_val, y_val, weight=val_weight)\r\n","            self.model = xgb.train(params=params,\r\n","                                   dtrain=self.trn_data,\r\n","                                   evals=[(self.trn_data, \"train\"), (self.val_data, \"val\")],\r\n","                                   **train_params)\r\n","        elif self.model_type == \"cat\":\r\n","            self.trn_data = Pool(\r\n","                X_train, label=y_train, cat_features=cat_cols)  #, group_id=[0] * len(X_train))\r\n","            self.val_data = Pool(\r\n","                X_val, label=y_val, cat_features=cat_cols)  #, group_id=[0] * len(X_val))\r\n","            self.model = CatBoost(params)\r\n","            self.model.fit(\r\n","                self.trn_data, eval_set=[self.val_data], use_best_model=True, **train_params)\r\n","        else:\r\n","            raise NotImplementedError\r\n","\r\n","    def predict(self, X: pd.DataFrame):\r\n","        if self.model_type == \"lgb\":\r\n","            return self.model.predict(\r\n","                X, num_iteration=self.model.best_iteration)  # type: ignore\r\n","        elif self.model_type == \"xgb\":\r\n","            X_DM = xgb.DMatrix(X)\r\n","            return self.model.predict(\r\n","                X_DM, ntree_limit=self.model.best_ntree_limit)  # type: ignore\r\n","        elif self.model_type == \"cat\":\r\n","            return self.model.predict(X)\r\n","        else:\r\n","            raise NotImplementedError\r\n","\r\n","    @property\r\n","    def feature_names_(self):\r\n","        if self.model_type == \"lgb\":\r\n","            return self.model.feature_name()\r\n","        elif self.model_type == \"xgb\":\r\n","            return list(self.model.get_score(importance_type=\"gain\").keys())\r\n","        elif self.model_type == \"cat\":\r\n","             return self.model.feature_names_\r\n","        else:\r\n","            raise NotImplementedError\r\n","\r\n","    @property\r\n","    def feature_importances_(self):\r\n","        if self.model_type == \"lgb\":\r\n","            return self.model.feature_importance(importance_type=\"gain\")\r\n","        elif self.model_type == \"xgb\":\r\n","            return list(self.model.get_score(importance_type=\"gain\").values())\r\n","        elif self.model_type == \"cat\":\r\n","            return self.model.feature_importances_\r\n","        else:\r\n","            raise NotImplementedError"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":865,"status":"ok","timestamp":1614082560378,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"2QwearY7HXXD"},"outputs":[],"source":["ID_COL = \"id\"\r\n","CAT_COLS= [f\"cat{i}\" for i in range(10)]\r\n","CONT_COLS = [f\"cont{i}\" for i in range(14)]\r\n","TGT_COL = \"target\"\r\n","\r\n","N_SPLITS = 10\r\n","RANDOM_SEED_LIST = [\r\n","    42\r\n","]"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":847,"status":"ok","timestamp":1614082588429,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"5LNWAJy6HFNk"},"outputs":[],"source":["use_feat_cols = []\r\n","train_feat = train[[ID_COL]].copy()\r\n","test_feat = test[[ID_COL]].copy()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1847,"status":"ok","timestamp":1614082604463,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"2E43zYzFI2_K","outputId":"7ff89b9d-4de6-410a-d14a-cb860a4b8701"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","  elif pd.api.types.is_categorical(cols):\n"]}],"source":["ord_enc = ce.OrdinalEncoder(cols=CAT_COLS)\r\n","train_cat_feat = ord_enc.fit_transform(train[CAT_COLS])\r\n","test_cat_feat = ord_enc.transform(test[CAT_COLS])"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":894,"status":"ok","timestamp":1614082623802,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"A1yeyUaiOxYr"},"outputs":[],"source":["train_feat = pd.concat([\r\n","    train_feat, train_cat_feat], axis=1)\r\n","test_feat = pd.concat([\r\n","    test_feat, test_cat_feat], axis=1)\r\n","use_feat_cols.extend(train_cat_feat.columns)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":969,"status":"ok","timestamp":1614082632082,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"AJJYaEa_OvZi"},"outputs":[],"source":["train_cont_feat = train[CONT_COLS]\r\n","test_cont_feat = test[CONT_COLS]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":879,"status":"ok","timestamp":1614082642378,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"XjJiofGzSde-"},"outputs":[],"source":["train_feat = pd.concat([\r\n","    train_feat, train_cont_feat], axis=1)\r\n","test_feat = pd.concat([\r\n","    test_feat, test_cont_feat], axis=1)\r\n","use_feat_cols.extend(CONT_COLS)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"executionInfo":{"elapsed":887,"status":"ok","timestamp":1614082659849,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"-EWdMqS96y-N","outputId":"90abdb6a-f80a-42b4-9878-e1f97848a1ff"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e3.000000\u003c/td\u003e\n","      \u003ctd\u003e4.000000\u003c/td\u003e\n","      \u003ctd\u003e6.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat0\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat1\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat2\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat3\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat4\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat5\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat6\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat7\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat8\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e3.000000\u003c/td\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ecat9\u003c/th\u003e\n","      \u003ctd\u003e1.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","      \u003ctd\u003e3.000000\u003c/td\u003e\n","      \u003ctd\u003e4.000000\u003c/td\u003e\n","      \u003ctd\u003e2.000000\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt0\u003c/th\u003e\n","      \u003ctd\u003e0.923191\u003c/td\u003e\n","      \u003ctd\u003e0.437627\u003c/td\u003e\n","      \u003ctd\u003e0.732209\u003c/td\u003e\n","      \u003ctd\u003e0.705142\u003c/td\u003e\n","      \u003ctd\u003e0.486063\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt1\u003c/th\u003e\n","      \u003ctd\u003e0.684968\u003c/td\u003e\n","      \u003ctd\u003e0.014213\u003c/td\u003e\n","      \u003ctd\u003e0.760122\u003c/td\u003e\n","      \u003ctd\u003e0.771678\u003c/td\u003e\n","      \u003ctd\u003e0.639349\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt2\u003c/th\u003e\n","      \u003ctd\u003e0.124454\u003c/td\u003e\n","      \u003ctd\u003e0.357438\u003c/td\u003e\n","      \u003ctd\u003e0.454644\u003c/td\u003e\n","      \u003ctd\u003e0.153735\u003c/td\u003e\n","      \u003ctd\u003e0.496212\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt3\u003c/th\u003e\n","      \u003ctd\u003e0.217886\u003c/td\u003e\n","      \u003ctd\u003e0.846127\u003c/td\u003e\n","      \u003ctd\u003e0.812990\u003c/td\u003e\n","      \u003ctd\u003e0.732893\u003c/td\u003e\n","      \u003ctd\u003e0.354186\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt4\u003c/th\u003e\n","      \u003ctd\u003e0.281421\u003c/td\u003e\n","      \u003ctd\u003e0.282354\u003c/td\u003e\n","      \u003ctd\u003e0.293756\u003c/td\u003e\n","      \u003ctd\u003e0.769785\u003c/td\u003e\n","      \u003ctd\u003e0.279105\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt5\u003c/th\u003e\n","      \u003ctd\u003e0.881122\u003c/td\u003e\n","      \u003ctd\u003e0.440011\u003c/td\u003e\n","      \u003ctd\u003e0.914155\u003c/td\u003e\n","      \u003ctd\u003e0.934138\u003c/td\u003e\n","      \u003ctd\u003e0.382600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt6\u003c/th\u003e\n","      \u003ctd\u003e0.421650\u003c/td\u003e\n","      \u003ctd\u003e0.346230\u003c/td\u003e\n","      \u003ctd\u003e0.369602\u003c/td\u003e\n","      \u003ctd\u003e0.578930\u003c/td\u003e\n","      \u003ctd\u003e0.705940\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt7\u003c/th\u003e\n","      \u003ctd\u003e0.741413\u003c/td\u003e\n","      \u003ctd\u003e0.278495\u003c/td\u003e\n","      \u003ctd\u003e0.832564\u003c/td\u003e\n","      \u003ctd\u003e0.407313\u003c/td\u003e\n","      \u003ctd\u003e0.325193\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt8\u003c/th\u003e\n","      \u003ctd\u003e0.895799\u003c/td\u003e\n","      \u003ctd\u003e0.593413\u003c/td\u003e\n","      \u003ctd\u003e0.865620\u003c/td\u003e\n","      \u003ctd\u003e0.868099\u003c/td\u003e\n","      \u003ctd\u003e0.440967\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt9\u003c/th\u003e\n","      \u003ctd\u003e0.802461\u003c/td\u003e\n","      \u003ctd\u003e0.546056\u003c/td\u003e\n","      \u003ctd\u003e0.825251\u003c/td\u003e\n","      \u003ctd\u003e0.794402\u003c/td\u003e\n","      \u003ctd\u003e0.462146\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt10\u003c/th\u003e\n","      \u003ctd\u003e0.724417\u003c/td\u003e\n","      \u003ctd\u003e0.613252\u003c/td\u003e\n","      \u003ctd\u003e0.264104\u003c/td\u003e\n","      \u003ctd\u003e0.494269\u003c/td\u003e\n","      \u003ctd\u003e0.724447\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt11\u003c/th\u003e\n","      \u003ctd\u003e0.701915\u003c/td\u003e\n","      \u003ctd\u003e0.741289\u003c/td\u003e\n","      \u003ctd\u003e0.695561\u003c/td\u003e\n","      \u003ctd\u003e0.698125\u003c/td\u003e\n","      \u003ctd\u003e0.683073\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt12\u003c/th\u003e\n","      \u003ctd\u003e0.877618\u003c/td\u003e\n","      \u003ctd\u003e0.326679\u003c/td\u003e\n","      \u003ctd\u003e0.869133\u003c/td\u003e\n","      \u003ctd\u003e0.809799\u003c/td\u003e\n","      \u003ctd\u003e0.343457\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003econt13\u003c/th\u003e\n","      \u003ctd\u003e0.719903\u003c/td\u003e\n","      \u003ctd\u003e0.808464\u003c/td\u003e\n","      \u003ctd\u003e0.828352\u003c/td\u003e\n","      \u003ctd\u003e0.614766\u003c/td\u003e\n","      \u003ctd\u003e0.297743\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["               0         1         2         3         4\n","id      1.000000  2.000000  3.000000  4.000000  6.000000\n","cat0    1.000000  2.000000  1.000000  1.000000  1.000000\n","cat1    1.000000  2.000000  2.000000  2.000000  1.000000\n","cat2    1.000000  1.000000  1.000000  1.000000  1.000000\n","cat3    1.000000  1.000000  2.000000  2.000000  1.000000\n","cat4    1.000000  1.000000  1.000000  1.000000  1.000000\n","cat5    1.000000  2.000000  1.000000  1.000000  2.000000\n","cat6    1.000000  1.000000  1.000000  1.000000  1.000000\n","cat7    1.000000  1.000000  2.000000  1.000000  1.000000\n","cat8    1.000000  2.000000  1.000000  3.000000  1.000000\n","cat9    1.000000  2.000000  3.000000  4.000000  2.000000\n","cont0   0.923191  0.437627  0.732209  0.705142  0.486063\n","cont1   0.684968  0.014213  0.760122  0.771678  0.639349\n","cont2   0.124454  0.357438  0.454644  0.153735  0.496212\n","cont3   0.217886  0.846127  0.812990  0.732893  0.354186\n","cont4   0.281421  0.282354  0.293756  0.769785  0.279105\n","cont5   0.881122  0.440011  0.914155  0.934138  0.382600\n","cont6   0.421650  0.346230  0.369602  0.578930  0.705940\n","cont7   0.741413  0.278495  0.832564  0.407313  0.325193\n","cont8   0.895799  0.593413  0.865620  0.868099  0.440967\n","cont9   0.802461  0.546056  0.825251  0.794402  0.462146\n","cont10  0.724417  0.613252  0.264104  0.494269  0.724447\n","cont11  0.701915  0.741289  0.695561  0.698125  0.683073\n","cont12  0.877618  0.326679  0.869133  0.809799  0.343457\n","cont13  0.719903  0.808464  0.828352  0.614766  0.297743"]},"execution_count":19,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["train_feat.head().T"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":891,"status":"ok","timestamp":1614082685412,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"hRSZKJgv_3zB"},"outputs":[],"source":["def run_train_and_inference(\r\n","    X, X_test, y, use_model, model_params, train_params, seed_list, n_splits, cat_cols=None\r\n","):\r\n","    \r\n","    oof_pred_arr = np.zeros(len(X))\r\n","    test_pred_arr = np.zeros(len(X_test))\r\n","    feature_importances = pd.DataFrame()\r\n","    score_list = []\r\n","    \r\n","    for seed in seed_list:\r\n","        if use_model == \"cat\":\r\n","            model_params['random_state'] = seed\r\n","        else:\r\n","            model_params[\"seed\"] = seed\r\n","        kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\r\n","        tmp_oof_pred = np.zeros(len(X))\r\n","        tmp_test_pred = np.zeros(len(X_test))\r\n","\r\n","        for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\r\n","            print(\"*\" * 100)\r\n","            print(f\"Seed: {seed} - Fold: {fold}\")\r\n","            X_trn = X.loc[trn_idx].reset_index(drop=True)\r\n","            X_val = X.loc[val_idx].reset_index(drop=True)\r\n","            y_trn = y[trn_idx]\r\n","            y_val = y[val_idx]\r\n","\r\n","            model = TreeModel(model_type=use_model)\r\n","            with timer(prefix=\"Model training\"):\r\n","                model.train(\r\n","                    params=model_params, X_train=X_trn, y_train=y_trn,\r\n","                    X_val=X_val, y_val=y_val, train_params=train_params, cat_cols=cat_cols\r\n","                )\r\n","            with timer(prefix=\"Get Feature Importance\"):\r\n","                fi_tmp = pd.DataFrame()\r\n","                fi_tmp[\"feature\"] = model.feature_names_\r\n","                fi_tmp[\"importance\"] = model.feature_importances_\r\n","                fi_tmp[\"fold\"] = fold\r\n","                fi_tmp[\"seed\"] = seed\r\n","                feature_importances = feature_importances.append(fi_tmp)\r\n","\r\n","            with timer(prefix=\"Predict Valid\"):\r\n","                val_pred = model.predict(X_val)\r\n","                score = mean_squared_error(y_val, val_pred, squared=False)\r\n","                # score = rmse(y_val, val_pred)\r\n","                print(f\"score: {score:.5f}\")\r\n","                score_list.append([seed, fold, score])\r\n","                tmp_oof_pred[val_idx] = val_pred\r\n","                tmp_test_pred += model.predict(X_test)\r\n","            \r\n","        oof_score = mean_squared_error(y, tmp_oof_pred, squared=False)\r\n","        # oof_score = rmse(y, tmp_oof_pred)\r\n","        print(f\"oof score: {oof_score: 5f}\")\r\n","        score_list.append([seed, \"oof\", oof_score])\r\n","\r\n","        oof_pred_arr += tmp_oof_pred\r\n","        test_pred_arr += tmp_test_pred / n_splits\r\n","\r\n","    oof_pred_arr /= len(seed_list)\r\n","    test_pred_arr /= len(seed_list)\r\n","    \r\n","    oof_score = mean_squared_error(y, oof_pred_arr, squared=False)\r\n","    # oof_score = rmse(y, oof_pred_arr)\r\n","    score_list.append([\"avg\", \"oof\", oof_score])\r\n","    score_df = pd.DataFrame(\r\n","        score_list, columns=[\"seed\", \"fold\", \"rmse score\"])\r\n","    \r\n","    return oof_pred_arr, test_pred_arr, score_df, feature_importances"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1614082722822,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"qWlezFppBdrB","outputId":"c42b4061-204c-4cfb-8fdc-ae4aa3dc012f"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_feat: (300000, 24), test_feat: (200000, 24)\n"]}],"source":["X = train_feat[use_feat_cols]\r\n","X_test = test_feat[use_feat_cols]\r\n","\r\n","y = train[TGT_COL].values\r\n","\r\n","print(f\"train_feat: {X.shape}, test_feat: {X_test.shape}\")"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":859,"status":"ok","timestamp":1614082730380,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"mq_GkSf4j-x4"},"outputs":[],"source":["X_cat = X.copy()\r\n","X_cat[CAT_COLS] = train[CAT_COLS]\r\n","X_test_cat = X_test.copy()\r\n","X_test_cat = test[CAT_COLS]"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":945,"status":"ok","timestamp":1614086668990,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"cnRq8QlkkAvj"},"outputs":[],"source":["MODEL_PARAMS = {\r\n","    \"lgb\": {\r\n","        \"objective\": \"root_mean_squared_error\",\r\n","        \"boosting\": \"gbdt\",\r\n","        \"max_depth\": 8,\r\n","        \"learning_rate\": 0.005,\r\n","        \"colsample_bytree\": 0.2,\r\n","        \"subsample\": 0.8,\r\n","        \"subsample_freq\": 6,\r\n","        \"reg_alpha\": 20,\r\n","        \"min_data_in_leaf\": 200,\r\n","        \"n_jobs\": 2,\r\n","        \"seed\": RANDOM_SEED_LIST[0],\r\n","        # \"device\": \"gpu\",\r\n","        # \"gpu_device_id\": 0\r\n","    },\r\n","    \"xgb\": {\r\n","        \"objective\": \"reg:squarederror\",\r\n","        \"max_depth\": 8,\r\n","        \"learning_rate\": 0.003,\r\n","        \"colsample_bytree\": 0.2,\r\n","        \"subsample\": 0.8,\r\n","        \"reg_alpha\" : 6,\r\n","        \"min_child_weight\": 200,\r\n","        \"n_jobs\": 2,\r\n","        \"seed\": RANDOM_SEED_LIST[0]\r\n","    },\r\n","    \"cat\": {\r\n","        'loss_function': 'RMSE',\r\n","        \"max_depth\": 4,\r\n","        'learning_rate': 0.03,\r\n","        \"bootstrap_type\": 'Poisson',\r\n","        \"subsample\": 0.8,\r\n","        \"border_count\": 512,\r\n","        \"l2_leaf_reg\": 200,\r\n","        'random_state': RANDOM_SEED_LIST[0],\r\n","        \"thread_count\": 2,\r\n","        'num_boost_round': 50000,\r\n","    }\r\n","}\r\n","TRAIN_PARAMS = {\r\n","    \"lgb\": {\r\n","        \"num_boost_round\": 50000,\r\n","        \"early_stopping_rounds\": 200,\r\n","        \"verbose_eval\": 200,\r\n","    },\r\n","    \"xgb\": {\r\n","        \"num_boost_round\": 50000,\r\n","        \"early_stopping_rounds\": 200,\r\n","        \"verbose_eval\":  200,\r\n","    },\r\n","    \"cat\": {\r\n","        'early_stopping_rounds': 200,\r\n","        'verbose_eval': 200,\r\n","    }\r\n","}"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3237926,"status":"ok","timestamp":1614086168088,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"80khFBXz1HDh","outputId":"7c1eef1f-d9c4-4df1-94e1-93318b5852b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["****************************************************************************************************\n","Seed: 42 - Fold: 0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032701 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3634\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456253\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.872475\tvalid_1's rmse: 0.876481\n","[400]\ttraining's rmse: 0.862942\tvalid_1's rmse: 0.867354\n","[600]\ttraining's rmse: 0.856622\tvalid_1's rmse: 0.861418\n","[800]\ttraining's rmse: 0.852254\tvalid_1's rmse: 0.857437\n","[1000]\ttraining's rmse: 0.849097\tvalid_1's rmse: 0.854685\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.846832\tvalid_1's rmse: 0.852776\n","[1400]\ttraining's rmse: 0.844987\tvalid_1's rmse: 0.851346\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.84349\tvalid_1's rmse: 0.850222\n","[1800]\ttraining's rmse: 0.84222\tvalid_1's rmse: 0.849361\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841109\tvalid_1's rmse: 0.848637\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840159\tvalid_1's rmse: 0.848079\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839317\tvalid_1's rmse: 0.847616\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838571\tvalid_1's rmse: 0.847236\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.837863\tvalid_1's rmse: 0.846908\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837201\tvalid_1's rmse: 0.846608\n","[3200]\ttraining's rmse: 0.836596\tvalid_1's rmse: 0.846383\n","[3400]\ttraining's rmse: 0.836048\tvalid_1's rmse: 0.846219\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835517\tvalid_1's rmse: 0.846054\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835008\tvalid_1's rmse: 0.845907\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834516\tvalid_1's rmse: 0.84575\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.83406\tvalid_1's rmse: 0.845623\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833619\tvalid_1's rmse: 0.845528\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833197\tvalid_1's rmse: 0.845444\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.832801\tvalid_1's rmse: 0.845382\n","[5000]\ttraining's rmse: 0.832409\tvalid_1's rmse: 0.845328\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832014\tvalid_1's rmse: 0.845289\n","[5400]\ttraining's rmse: 0.831629\tvalid_1's rmse: 0.845228\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5600]\ttraining's rmse: 0.831257\tvalid_1's rmse: 0.845178\n","[5800]\ttraining's rmse: 0.830894\tvalid_1's rmse: 0.845143\n","[6000]\ttraining's rmse: 0.830537\tvalid_1's rmse: 0.845107\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.83019\tvalid_1's rmse: 0.845075\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.829856\tvalid_1's rmse: 0.845048\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829526\tvalid_1's rmse: 0.845015\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829184\tvalid_1's rmse: 0.844981\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.828868\tvalid_1's rmse: 0.844966\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828538\tvalid_1's rmse: 0.844946\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828222\tvalid_1's rmse: 0.84494\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Early stopping, best iteration is:\n","[7323]\ttraining's rmse: 0.828346\tvalid_1's rmse: 0.844935\n","Model training152.796[s]\n","Get Feature Importance0.006[s]\n","score: 0.84494\n","Predict Valid110.998[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 1\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030196 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3636\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456392\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.87294\tvalid_1's rmse: 0.872074\n","[400]\ttraining's rmse: 0.863474\tvalid_1's rmse: 0.862556\n","[600]\ttraining's rmse: 0.857192\tvalid_1's rmse: 0.856339\n","[800]\ttraining's rmse: 0.852855\tvalid_1's rmse: 0.852179\n","[1000]\ttraining's rmse: 0.849735\tvalid_1's rmse: 0.849279\n","[1200]\ttraining's rmse: 0.847473\tvalid_1's rmse: 0.84727\n","[1400]\ttraining's rmse: 0.845651\tvalid_1's rmse: 0.845731\n","[1600]\ttraining's rmse: 0.844157\tvalid_1's rmse: 0.844543\n","[1800]\ttraining's rmse: 0.842891\tvalid_1's rmse: 0.84361\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841794\tvalid_1's rmse: 0.842829\n","[2200]\ttraining's rmse: 0.840832\tvalid_1's rmse: 0.842196\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.840007\tvalid_1's rmse: 0.841696\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.839259\tvalid_1's rmse: 0.841279\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838558\tvalid_1's rmse: 0.840913\n","[3000]\ttraining's rmse: 0.837902\tvalid_1's rmse: 0.840588\n","[3200]\ttraining's rmse: 0.837297\tvalid_1's rmse: 0.840316\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3400]\ttraining's rmse: 0.836749\tvalid_1's rmse: 0.840089\n","[3600]\ttraining's rmse: 0.836214\tvalid_1's rmse: 0.839908\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835709\tvalid_1's rmse: 0.839724\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.835237\tvalid_1's rmse: 0.839572\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834777\tvalid_1's rmse: 0.839441\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.834334\tvalid_1's rmse: 0.839329\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833917\tvalid_1's rmse: 0.839225\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833516\tvalid_1's rmse: 0.839142\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5000]\ttraining's rmse: 0.833125\tvalid_1's rmse: 0.839073\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832731\tvalid_1's rmse: 0.839015\n","[5400]\ttraining's rmse: 0.832349\tvalid_1's rmse: 0.838927\n","[5600]\ttraining's rmse: 0.831979\tvalid_1's rmse: 0.838875\n","[5800]\ttraining's rmse: 0.831617\tvalid_1's rmse: 0.838822\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.831257\tvalid_1's rmse: 0.838794\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830912\tvalid_1's rmse: 0.83876\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830573\tvalid_1's rmse: 0.838722\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.830245\tvalid_1's rmse: 0.838691\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829908\tvalid_1's rmse: 0.838653\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829582\tvalid_1's rmse: 0.838629\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.829254\tvalid_1's rmse: 0.838602\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828937\tvalid_1's rmse: 0.838584\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.82863\tvalid_1's rmse: 0.838563\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.828321\tvalid_1's rmse: 0.838549\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.828016\tvalid_1's rmse: 0.838534\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827711\tvalid_1's rmse: 0.838512\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.827409\tvalid_1's rmse: 0.8385\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.827113\tvalid_1's rmse: 0.838499\n","[8800]\ttraining's rmse: 0.826814\tvalid_1's rmse: 0.838481\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[9000]\ttraining's rmse: 0.826519\tvalid_1's rmse: 0.838473\n","[9200]\ttraining's rmse: 0.826215\tvalid_1's rmse: 0.838471\n","Early stopping, best iteration is:\n","[9107]\ttraining's rmse: 0.826354\tvalid_1's rmse: 0.838465\n","Model training184.153[s]\n","Get Feature Importance0.007[s]\n","score: 0.83847\n","Predict Valid162.774[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 2\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029391 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.458208\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.872501\tvalid_1's rmse: 0.875533\n","[400]\ttraining's rmse: 0.862919\tvalid_1's rmse: 0.866716\n","[600]\ttraining's rmse: 0.856547\tvalid_1's rmse: 0.86097\n","[800]\ttraining's rmse: 0.852208\tvalid_1's rmse: 0.857186\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849092\tvalid_1's rmse: 0.854539\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.84681\tvalid_1's rmse: 0.852719\n","[1400]\ttraining's rmse: 0.844979\tvalid_1's rmse: 0.851318\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.843487\tvalid_1's rmse: 0.85023\n","[1800]\ttraining's rmse: 0.842209\tvalid_1's rmse: 0.849371\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841124\tvalid_1's rmse: 0.848681\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840184\tvalid_1's rmse: 0.848129\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839344\tvalid_1's rmse: 0.847655\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838602\tvalid_1's rmse: 0.847275\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.837897\tvalid_1's rmse: 0.84694\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837246\tvalid_1's rmse: 0.846631\n","[3200]\ttraining's rmse: 0.836639\tvalid_1's rmse: 0.846366\n","[3400]\ttraining's rmse: 0.836084\tvalid_1's rmse: 0.84616\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.83555\tvalid_1's rmse: 0.845962\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835046\tvalid_1's rmse: 0.845805\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834564\tvalid_1's rmse: 0.845656\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834098\tvalid_1's rmse: 0.845528\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833663\tvalid_1's rmse: 0.84543\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833251\tvalid_1's rmse: 0.845337\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.832847\tvalid_1's rmse: 0.845263\n","[5000]\ttraining's rmse: 0.832451\tvalid_1's rmse: 0.845201\n","[5200]\ttraining's rmse: 0.832055\tvalid_1's rmse: 0.845131\n","[5400]\ttraining's rmse: 0.831676\tvalid_1's rmse: 0.845053\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5600]\ttraining's rmse: 0.831297\tvalid_1's rmse: 0.845011\n","[5800]\ttraining's rmse: 0.830929\tvalid_1's rmse: 0.844955\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.830577\tvalid_1's rmse: 0.844904\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830227\tvalid_1's rmse: 0.844872\n","[6400]\ttraining's rmse: 0.829887\tvalid_1's rmse: 0.844847\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829549\tvalid_1's rmse: 0.844821\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.82921\tvalid_1's rmse: 0.844789\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.828889\tvalid_1's rmse: 0.844769\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828562\tvalid_1's rmse: 0.844747\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828254\tvalid_1's rmse: 0.844734\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.827948\tvalid_1's rmse: 0.844726\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.827647\tvalid_1's rmse: 0.844718\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827342\tvalid_1's rmse: 0.8447\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827037\tvalid_1's rmse: 0.844691\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.826729\tvalid_1's rmse: 0.844676\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.826432\tvalid_1's rmse: 0.844679\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8800]\ttraining's rmse: 0.826132\tvalid_1's rmse: 0.844671\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Early stopping, best iteration is:\n","[8730]\ttraining's rmse: 0.826236\tvalid_1's rmse: 0.844663\n","Model training177.046[s]\n","Get Feature Importance0.007[s]\n","score: 0.84466\n","Predict Valid148.680[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 3\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030706 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.455414\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.87284\tvalid_1's rmse: 0.872381\n","[400]\ttraining's rmse: 0.863239\tvalid_1's rmse: 0.863697\n","[600]\ttraining's rmse: 0.85682\tvalid_1's rmse: 0.858075\n","[800]\ttraining's rmse: 0.852438\tvalid_1's rmse: 0.854401\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849293\tvalid_1's rmse: 0.851872\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.847006\tvalid_1's rmse: 0.850159\n","[1400]\ttraining's rmse: 0.845153\tvalid_1's rmse: 0.848863\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.843657\tvalid_1's rmse: 0.847871\n","[1800]\ttraining's rmse: 0.842381\tvalid_1's rmse: 0.847064\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841281\tvalid_1's rmse: 0.846418\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.84033\tvalid_1's rmse: 0.84589\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839502\tvalid_1's rmse: 0.845465\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838745\tvalid_1's rmse: 0.845125\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838045\tvalid_1's rmse: 0.844819\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837378\tvalid_1's rmse: 0.844542\n","[3200]\ttraining's rmse: 0.836769\tvalid_1's rmse: 0.844315\n","[3400]\ttraining's rmse: 0.836223\tvalid_1's rmse: 0.844153\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835687\tvalid_1's rmse: 0.843976\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.83518\tvalid_1's rmse: 0.843815\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834702\tvalid_1's rmse: 0.843687\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834239\tvalid_1's rmse: 0.843569\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833807\tvalid_1's rmse: 0.843462\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833391\tvalid_1's rmse: 0.843374\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.832983\tvalid_1's rmse: 0.843301\n","[5000]\ttraining's rmse: 0.832592\tvalid_1's rmse: 0.84322\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832201\tvalid_1's rmse: 0.843153\n","[5400]\ttraining's rmse: 0.831821\tvalid_1's rmse: 0.843091\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5600]\ttraining's rmse: 0.831455\tvalid_1's rmse: 0.843046\n","[5800]\ttraining's rmse: 0.831096\tvalid_1's rmse: 0.843012\n","[6000]\ttraining's rmse: 0.830731\tvalid_1's rmse: 0.842989\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.83038\tvalid_1's rmse: 0.842952\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830047\tvalid_1's rmse: 0.842909\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.82972\tvalid_1's rmse: 0.842882\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829385\tvalid_1's rmse: 0.842859\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829069\tvalid_1's rmse: 0.842839\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.82874\tvalid_1's rmse: 0.842814\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828431\tvalid_1's rmse: 0.842793\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828126\tvalid_1's rmse: 0.842773\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.827818\tvalid_1's rmse: 0.842739\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827512\tvalid_1's rmse: 0.842716\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827205\tvalid_1's rmse: 0.842694\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.826896\tvalid_1's rmse: 0.842681\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.826604\tvalid_1's rmse: 0.84267\n","[8800]\ttraining's rmse: 0.826304\tvalid_1's rmse: 0.842662\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[9000]\ttraining's rmse: 0.826002\tvalid_1's rmse: 0.842655\n","[9200]\ttraining's rmse: 0.825699\tvalid_1's rmse: 0.842642\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[9400]\ttraining's rmse: 0.825411\tvalid_1's rmse: 0.842643\n","Early stopping, best iteration is:\n","[9238]\ttraining's rmse: 0.825646\tvalid_1's rmse: 0.842638\n","Model training188.509[s]\n","Get Feature Importance0.007[s]\n","score: 0.84264\n","Predict Valid167.540[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 4\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029015 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456023\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.87287\tvalid_1's rmse: 0.872309\n","[400]\ttraining's rmse: 0.863321\tvalid_1's rmse: 0.863415\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[600]\ttraining's rmse: 0.856956\tvalid_1's rmse: 0.857623\n","[800]\ttraining's rmse: 0.852594\tvalid_1's rmse: 0.853798\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849465\tvalid_1's rmse: 0.851151\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.847184\tvalid_1's rmse: 0.849341\n","[1400]\ttraining's rmse: 0.845348\tvalid_1's rmse: 0.847931\n","[1600]\ttraining's rmse: 0.843857\tvalid_1's rmse: 0.846838\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1800]\ttraining's rmse: 0.842598\tvalid_1's rmse: 0.845949\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841514\tvalid_1's rmse: 0.845212\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840576\tvalid_1's rmse: 0.844634\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839739\tvalid_1's rmse: 0.844129\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838992\tvalid_1's rmse: 0.843689\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838286\tvalid_1's rmse: 0.843334\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837636\tvalid_1's rmse: 0.84303\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3200]\ttraining's rmse: 0.837033\tvalid_1's rmse: 0.842738\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3400]\ttraining's rmse: 0.836477\tvalid_1's rmse: 0.842494\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835947\tvalid_1's rmse: 0.842263\n","[3800]\ttraining's rmse: 0.835442\tvalid_1's rmse: 0.842078\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834972\tvalid_1's rmse: 0.841897\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834521\tvalid_1's rmse: 0.841758\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.834088\tvalid_1's rmse: 0.841632\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833671\tvalid_1's rmse: 0.841521\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833258\tvalid_1's rmse: 0.841428\n","[5000]\ttraining's rmse: 0.832862\tvalid_1's rmse: 0.841354\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832461\tvalid_1's rmse: 0.841271\n","[5400]\ttraining's rmse: 0.832085\tvalid_1's rmse: 0.841192\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5600]\ttraining's rmse: 0.831711\tvalid_1's rmse: 0.841132\n","[5800]\ttraining's rmse: 0.831346\tvalid_1's rmse: 0.841071\n","[6000]\ttraining's rmse: 0.83099\tvalid_1's rmse: 0.841026\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830637\tvalid_1's rmse: 0.840988\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830296\tvalid_1's rmse: 0.840947\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829965\tvalid_1's rmse: 0.840899\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829624\tvalid_1's rmse: 0.840842\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829304\tvalid_1's rmse: 0.840815\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828978\tvalid_1's rmse: 0.840766\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.82867\tvalid_1's rmse: 0.840748\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828359\tvalid_1's rmse: 0.840724\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.828049\tvalid_1's rmse: 0.840691\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827737\tvalid_1's rmse: 0.840663\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827432\tvalid_1's rmse: 0.840655\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.827124\tvalid_1's rmse: 0.840639\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.826825\tvalid_1's rmse: 0.84062\n","[8800]\ttraining's rmse: 0.82652\tvalid_1's rmse: 0.840608\n","[9000]\ttraining's rmse: 0.826217\tvalid_1's rmse: 0.840604\n","[9200]\ttraining's rmse: 0.825915\tvalid_1's rmse: 0.840592\n","[9400]\ttraining's rmse: 0.825625\tvalid_1's rmse: 0.840582\n","[9600]\ttraining's rmse: 0.825337\tvalid_1's rmse: 0.840566\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Early stopping, best iteration is:\n","[9592]\ttraining's rmse: 0.825346\tvalid_1's rmse: 0.840566\n","Model training191.455[s]\n","Get Feature Importance0.007[s]\n","score: 0.84057\n","Predict Valid181.520[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 5\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031417 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456705\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.872508\tvalid_1's rmse: 0.875785\n","[400]\ttraining's rmse: 0.86298\tvalid_1's rmse: 0.866734\n","[600]\ttraining's rmse: 0.85663\tvalid_1's rmse: 0.860809\n","[800]\ttraining's rmse: 0.852274\tvalid_1's rmse: 0.856826\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849153\tvalid_1's rmse: 0.854092\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.846889\tvalid_1's rmse: 0.852225\n","[1400]\ttraining's rmse: 0.845064\tvalid_1's rmse: 0.850798\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.843561\tvalid_1's rmse: 0.849672\n","[1800]\ttraining's rmse: 0.842289\tvalid_1's rmse: 0.848789\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841191\tvalid_1's rmse: 0.848067\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840255\tvalid_1's rmse: 0.847491\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839414\tvalid_1's rmse: 0.846991\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838677\tvalid_1's rmse: 0.846588\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.837968\tvalid_1's rmse: 0.84622\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837316\tvalid_1's rmse: 0.845903\n","[3200]\ttraining's rmse: 0.836714\tvalid_1's rmse: 0.845641\n","[3400]\ttraining's rmse: 0.836163\tvalid_1's rmse: 0.845425\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835637\tvalid_1's rmse: 0.845232\n","[3800]\ttraining's rmse: 0.835128\tvalid_1's rmse: 0.845066\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834656\tvalid_1's rmse: 0.844916\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834198\tvalid_1's rmse: 0.844775\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833766\tvalid_1's rmse: 0.844662\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833352\tvalid_1's rmse: 0.844557\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.832949\tvalid_1's rmse: 0.844484\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5000]\ttraining's rmse: 0.832563\tvalid_1's rmse: 0.844386\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832165\tvalid_1's rmse: 0.844309\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5400]\ttraining's rmse: 0.831793\tvalid_1's rmse: 0.844253\n","[5600]\ttraining's rmse: 0.831418\tvalid_1's rmse: 0.844183\n","[5800]\ttraining's rmse: 0.831052\tvalid_1's rmse: 0.844134\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.830698\tvalid_1's rmse: 0.844106\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830352\tvalid_1's rmse: 0.844077\n","[6400]\ttraining's rmse: 0.830018\tvalid_1's rmse: 0.844037\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829689\tvalid_1's rmse: 0.84402\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829352\tvalid_1's rmse: 0.843981\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829032\tvalid_1's rmse: 0.843962\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828696\tvalid_1's rmse: 0.843936\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828378\tvalid_1's rmse: 0.843919\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828065\tvalid_1's rmse: 0.843907\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.827759\tvalid_1's rmse: 0.843895\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.82745\tvalid_1's rmse: 0.843897\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827143\tvalid_1's rmse: 0.843872\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.826839\tvalid_1's rmse: 0.843865\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.826543\tvalid_1's rmse: 0.843859\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8800]\ttraining's rmse: 0.826237\tvalid_1's rmse: 0.843854\n","Early stopping, best iteration is:\n","[8663]\ttraining's rmse: 0.826445\tvalid_1's rmse: 0.843849\n","Model training177.513[s]\n","Get Feature Importance0.007[s]\n","score: 0.84385\n","Predict Valid152.817[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 6\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029953 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456435\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.872924\tvalid_1's rmse: 0.871211\n","[400]\ttraining's rmse: 0.863305\tvalid_1's rmse: 0.862502\n","[600]\ttraining's rmse: 0.856912\tvalid_1's rmse: 0.856947\n","[800]\ttraining's rmse: 0.85257\tvalid_1's rmse: 0.853275\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849431\tvalid_1's rmse: 0.850739\n","[1200]\ttraining's rmse: 0.847138\tvalid_1's rmse: 0.849025\n","[1400]\ttraining's rmse: 0.845315\tvalid_1's rmse: 0.84773\n","[1600]\ttraining's rmse: 0.843809\tvalid_1's rmse: 0.846708\n","[1800]\ttraining's rmse: 0.842551\tvalid_1's rmse: 0.845908\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841452\tvalid_1's rmse: 0.845237\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840513\tvalid_1's rmse: 0.844736\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839678\tvalid_1's rmse: 0.844274\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838937\tvalid_1's rmse: 0.843915\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838233\tvalid_1's rmse: 0.843598\n","[3000]\ttraining's rmse: 0.837569\tvalid_1's rmse: 0.84331\n","[3200]\ttraining's rmse: 0.836962\tvalid_1's rmse: 0.843081\n","[3400]\ttraining's rmse: 0.836413\tvalid_1's rmse: 0.842892\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835883\tvalid_1's rmse: 0.842716\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835369\tvalid_1's rmse: 0.842564\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834886\tvalid_1's rmse: 0.842417\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.83443\tvalid_1's rmse: 0.842282\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833998\tvalid_1's rmse: 0.84218\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833583\tvalid_1's rmse: 0.842075\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833183\tvalid_1's rmse: 0.84199\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5000]\ttraining's rmse: 0.8328\tvalid_1's rmse: 0.841923\n","[5200]\ttraining's rmse: 0.832405\tvalid_1's rmse: 0.841862\n","[5400]\ttraining's rmse: 0.832024\tvalid_1's rmse: 0.841793\n","[5600]\ttraining's rmse: 0.831656\tvalid_1's rmse: 0.841741\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5800]\ttraining's rmse: 0.831294\tvalid_1's rmse: 0.841688\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.830938\tvalid_1's rmse: 0.841643\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830593\tvalid_1's rmse: 0.841603\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830251\tvalid_1's rmse: 0.841567\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829918\tvalid_1's rmse: 0.84154\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829579\tvalid_1's rmse: 0.841502\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829258\tvalid_1's rmse: 0.841484\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828938\tvalid_1's rmse: 0.841458\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.82862\tvalid_1's rmse: 0.841449\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828315\tvalid_1's rmse: 0.841431\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.82801\tvalid_1's rmse: 0.841402\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827702\tvalid_1's rmse: 0.841385\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827397\tvalid_1's rmse: 0.841368\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.827095\tvalid_1's rmse: 0.841353\n","[8600]\ttraining's rmse: 0.8268\tvalid_1's rmse: 0.841355\n","Early stopping, best iteration is:\n","[8494]\ttraining's rmse: 0.826959\tvalid_1's rmse: 0.841348\n","Model training174.129[s]\n","Get Feature Importance0.007[s]\n","score: 0.84135\n","Predict Valid151.682[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 7\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030965 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3636\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.456183\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.872831\tvalid_1's rmse: 0.873147\n","[400]\ttraining's rmse: 0.863322\tvalid_1's rmse: 0.863944\n","[600]\ttraining's rmse: 0.856973\tvalid_1's rmse: 0.857946\n","[800]\ttraining's rmse: 0.852608\tvalid_1's rmse: 0.853975\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849484\tvalid_1's rmse: 0.851246\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1200]\ttraining's rmse: 0.847207\tvalid_1's rmse: 0.849409\n","[1400]\ttraining's rmse: 0.845362\tvalid_1's rmse: 0.847949\n","[1600]\ttraining's rmse: 0.843842\tvalid_1's rmse: 0.846835\n","[1800]\ttraining's rmse: 0.842584\tvalid_1's rmse: 0.845964\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841489\tvalid_1's rmse: 0.845264\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.840539\tvalid_1's rmse: 0.844684\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839707\tvalid_1's rmse: 0.844191\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838964\tvalid_1's rmse: 0.843795\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838247\tvalid_1's rmse: 0.843446\n","[3000]\ttraining's rmse: 0.837588\tvalid_1's rmse: 0.843159\n","[3200]\ttraining's rmse: 0.836981\tvalid_1's rmse: 0.842913\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3400]\ttraining's rmse: 0.836431\tvalid_1's rmse: 0.842697\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835905\tvalid_1's rmse: 0.842516\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835401\tvalid_1's rmse: 0.842365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834928\tvalid_1's rmse: 0.842236\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834461\tvalid_1's rmse: 0.842115\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.83402\tvalid_1's rmse: 0.841981\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833605\tvalid_1's rmse: 0.84189\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833208\tvalid_1's rmse: 0.841801\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5000]\ttraining's rmse: 0.832824\tvalid_1's rmse: 0.841733\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832426\tvalid_1's rmse: 0.841669\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5400]\ttraining's rmse: 0.832042\tvalid_1's rmse: 0.841607\n","[5600]\ttraining's rmse: 0.831664\tvalid_1's rmse: 0.841552\n","[5800]\ttraining's rmse: 0.831302\tvalid_1's rmse: 0.841512\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.830939\tvalid_1's rmse: 0.84147\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.83059\tvalid_1's rmse: 0.841429\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830254\tvalid_1's rmse: 0.841406\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829927\tvalid_1's rmse: 0.841389\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829588\tvalid_1's rmse: 0.841367\n","[7000]\ttraining's rmse: 0.82926\tvalid_1's rmse: 0.841339\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828934\tvalid_1's rmse: 0.84132\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.82862\tvalid_1's rmse: 0.841307\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828311\tvalid_1's rmse: 0.841293\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.828004\tvalid_1's rmse: 0.841276\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827694\tvalid_1's rmse: 0.841253\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827389\tvalid_1's rmse: 0.841239\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8400]\ttraining's rmse: 0.827081\tvalid_1's rmse: 0.841224\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8600]\ttraining's rmse: 0.826785\tvalid_1's rmse: 0.841213\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8800]\ttraining's rmse: 0.82649\tvalid_1's rmse: 0.841215\n","Early stopping, best iteration is:\n","[8613]\ttraining's rmse: 0.826765\tvalid_1's rmse: 0.841212\n","Model training175.610[s]\n","Get Feature Importance0.007[s]\n","score: 0.84121\n","Predict Valid147.360[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 8\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031752 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3634\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.455196\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.87257\tvalid_1's rmse: 0.876114\n","[400]\ttraining's rmse: 0.863099\tvalid_1's rmse: 0.866574\n","[600]\ttraining's rmse: 0.856775\tvalid_1's rmse: 0.860255\n","[800]\ttraining's rmse: 0.852443\tvalid_1's rmse: 0.856041\n","[1000]\ttraining's rmse: 0.849336\tvalid_1's rmse: 0.853113\n","[1200]\ttraining's rmse: 0.847064\tvalid_1's rmse: 0.851077\n","[1400]\ttraining's rmse: 0.845223\tvalid_1's rmse: 0.849543\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.843742\tvalid_1's rmse: 0.848387\n","[1800]\ttraining's rmse: 0.842461\tvalid_1's rmse: 0.847411\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841385\tvalid_1's rmse: 0.84664\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2200]\ttraining's rmse: 0.84043\tvalid_1's rmse: 0.846013\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839602\tvalid_1's rmse: 0.845503\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.838851\tvalid_1's rmse: 0.845104\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.83814\tvalid_1's rmse: 0.844729\n","[3000]\ttraining's rmse: 0.837482\tvalid_1's rmse: 0.844421\n","[3200]\ttraining's rmse: 0.836875\tvalid_1's rmse: 0.84416\n","[3400]\ttraining's rmse: 0.83632\tvalid_1's rmse: 0.843933\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.835798\tvalid_1's rmse: 0.843738\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.8353\tvalid_1's rmse: 0.84357\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.834832\tvalid_1's rmse: 0.843421\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834374\tvalid_1's rmse: 0.843284\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.833935\tvalid_1's rmse: 0.843159\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833514\tvalid_1's rmse: 0.843046\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833111\tvalid_1's rmse: 0.842973\n","[5000]\ttraining's rmse: 0.83272\tvalid_1's rmse: 0.84291\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832327\tvalid_1's rmse: 0.84285\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5400]\ttraining's rmse: 0.831945\tvalid_1's rmse: 0.842775\n","[5600]\ttraining's rmse: 0.831576\tvalid_1's rmse: 0.842721\n","[5800]\ttraining's rmse: 0.831215\tvalid_1's rmse: 0.842668\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.830858\tvalid_1's rmse: 0.842628\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830509\tvalid_1's rmse: 0.842592\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830173\tvalid_1's rmse: 0.842566\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.829843\tvalid_1's rmse: 0.842527\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829502\tvalid_1's rmse: 0.842497\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7000]\ttraining's rmse: 0.829184\tvalid_1's rmse: 0.842467\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.828855\tvalid_1's rmse: 0.842433\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.82854\tvalid_1's rmse: 0.84241\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.82823\tvalid_1's rmse: 0.842404\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.827925\tvalid_1's rmse: 0.842398\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Early stopping, best iteration is:\n","[7767]\ttraining's rmse: 0.827976\tvalid_1's rmse: 0.842389\n","Model training160.664[s]\n","Get Feature Importance0.006[s]\n","score: 0.84239\n","Predict Valid133.282[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 9\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030282 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3635\n","[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth \u003e num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Start training from score 7.455796\n","Training until validation scores don't improve for 200 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[200]\ttraining's rmse: 0.873308\tvalid_1's rmse: 0.86813\n","[400]\ttraining's rmse: 0.863688\tvalid_1's rmse: 0.859479\n","[600]\ttraining's rmse: 0.857294\tvalid_1's rmse: 0.853898\n","[800]\ttraining's rmse: 0.852887\tvalid_1's rmse: 0.850284\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1000]\ttraining's rmse: 0.849715\tvalid_1's rmse: 0.847839\n","[1200]\ttraining's rmse: 0.847444\tvalid_1's rmse: 0.846144\n","[1400]\ttraining's rmse: 0.845586\tvalid_1's rmse: 0.844848\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1600]\ttraining's rmse: 0.844085\tvalid_1's rmse: 0.843878\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[1800]\ttraining's rmse: 0.842809\tvalid_1's rmse: 0.843097\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2000]\ttraining's rmse: 0.841724\tvalid_1's rmse: 0.842467\n","[2200]\ttraining's rmse: 0.840777\tvalid_1's rmse: 0.841953\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2400]\ttraining's rmse: 0.839939\tvalid_1's rmse: 0.841521\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2600]\ttraining's rmse: 0.839198\tvalid_1's rmse: 0.841169\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[2800]\ttraining's rmse: 0.838492\tvalid_1's rmse: 0.84084\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3000]\ttraining's rmse: 0.837837\tvalid_1's rmse: 0.840557\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3200]\ttraining's rmse: 0.837235\tvalid_1's rmse: 0.840309\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3400]\ttraining's rmse: 0.836686\tvalid_1's rmse: 0.840096\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3600]\ttraining's rmse: 0.836161\tvalid_1's rmse: 0.839918\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[3800]\ttraining's rmse: 0.835653\tvalid_1's rmse: 0.839748\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4000]\ttraining's rmse: 0.835179\tvalid_1's rmse: 0.839619\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4200]\ttraining's rmse: 0.834727\tvalid_1's rmse: 0.839502\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4400]\ttraining's rmse: 0.834292\tvalid_1's rmse: 0.839403\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4600]\ttraining's rmse: 0.833876\tvalid_1's rmse: 0.83933\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[4800]\ttraining's rmse: 0.833471\tvalid_1's rmse: 0.839255\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5000]\ttraining's rmse: 0.833081\tvalid_1's rmse: 0.839186\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5200]\ttraining's rmse: 0.832693\tvalid_1's rmse: 0.839108\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[5400]\ttraining's rmse: 0.83232\tvalid_1's rmse: 0.839047\n","[5600]\ttraining's rmse: 0.831939\tvalid_1's rmse: 0.838998\n","[5800]\ttraining's rmse: 0.83157\tvalid_1's rmse: 0.838949\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6000]\ttraining's rmse: 0.831214\tvalid_1's rmse: 0.838914\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6200]\ttraining's rmse: 0.830863\tvalid_1's rmse: 0.838889\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6400]\ttraining's rmse: 0.830525\tvalid_1's rmse: 0.838853\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6600]\ttraining's rmse: 0.830192\tvalid_1's rmse: 0.838822\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[6800]\ttraining's rmse: 0.829852\tvalid_1's rmse: 0.838808\n","[7000]\ttraining's rmse: 0.829529\tvalid_1's rmse: 0.838784\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7200]\ttraining's rmse: 0.829198\tvalid_1's rmse: 0.838769\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7400]\ttraining's rmse: 0.828879\tvalid_1's rmse: 0.838744\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7600]\ttraining's rmse: 0.828566\tvalid_1's rmse: 0.838716\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[7800]\ttraining's rmse: 0.828258\tvalid_1's rmse: 0.838715\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8000]\ttraining's rmse: 0.827949\tvalid_1's rmse: 0.838687\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[8200]\ttraining's rmse: 0.827642\tvalid_1's rmse: 0.838699\n","Early stopping, best iteration is:\n","[8009]\ttraining's rmse: 0.827935\tvalid_1's rmse: 0.838686\n","Model training165.118[s]\n","Get Feature Importance0.007[s]\n","score: 0.83869\n","Predict Valid132.541[s]\n","oof score:  0.841878\n"]}],"source":["oof_pred_lgb, test_pred_lgb, score_lgb, feat_imps_lgb = run_train_and_inference(\r\n","    X, X_test, y, \"lgb\", MODEL_PARAMS[\"lgb\"], TRAIN_PARAMS[\"lgb\"], RANDOM_SEED_LIST, N_SPLITS)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":2389,"status":"ok","timestamp":1614086170489,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"RmeNlW-k2AR1","outputId":"abe22da2-828a-4431-efdd-14cb04bd877d"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eseed\u003c/th\u003e\n","      \u003cth\u003efold\u003c/th\u003e\n","      \u003cth\u003ermse score\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.844935\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.838465\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0.844663\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0.842638\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0.840566\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e0.843849\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e6\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.841348\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e0.841212\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e8\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e0.842389\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e9\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003e9\u003c/td\u003e\n","      \u003ctd\u003e0.838686\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e10\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003eoof\u003c/td\u003e\n","      \u003ctd\u003e0.841878\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e11\u003c/th\u003e\n","      \u003ctd\u003eavg\u003c/td\u003e\n","      \u003ctd\u003eoof\u003c/td\u003e\n","      \u003ctd\u003e0.841878\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   seed fold  rmse score\n","0    42    0    0.844935\n","1    42    1    0.838465\n","2    42    2    0.844663\n","3    42    3    0.842638\n","4    42    4    0.840566\n","5    42    5    0.843849\n","6    42    6    0.841348\n","7    42    7    0.841212\n","8    42    8    0.842389\n","9    42    9    0.838686\n","10   42  oof    0.841878\n","11  avg  oof    0.841878"]},"execution_count":27,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["score_lgb"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"elapsed":2385,"status":"ok","timestamp":1614086170490,"user":{"displayName":"‍최명진(사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"},"user_tz":-540},"id":"-r8NjBsl2BTd","outputId":"3f918496-2e7e-4002-beff-ef13ae896842"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eseed\u003c/th\u003e\n","      \u003cth\u003efold\u003c/th\u003e\n","      \u003cth\u003ermse score\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e10\u003c/th\u003e\n","      \u003ctd\u003e42\u003c/td\u003e\n","      \u003ctd\u003eoof\u003c/td\u003e\n","      \u003ctd\u003e0.841878\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e11\u003c/th\u003e\n","      \u003ctd\u003eavg\u003c/td\u003e\n","      \u003ctd\u003eoof\u003c/td\u003e\n","      \u003ctd\u003e0.841878\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   seed fold  rmse score\n","10   42  oof    0.841878\n","11  avg  oof    0.841878"]},"execution_count":28,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["score_lgb.loc[score_lgb.fold == \"oof\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3HQt0JMdB1k-"},"outputs":[{"name":"stdout","output_type":"stream","text":["****************************************************************************************************\n","Seed: 42 - Fold: 0\n","[0]\ttrain-rmse:6.99185\tval-rmse:6.99238\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90343\tval-rmse:3.9043\n","[400]\ttrain-rmse:2.26111\tval-rmse:2.2626\n","[600]\ttrain-rmse:1.43599\tval-rmse:1.43839\n","[800]\ttrain-rmse:1.06726\tval-rmse:1.07073\n","[1000]\ttrain-rmse:0.925471\tval-rmse:0.929951\n","[1200]\ttrain-rmse:0.875766\tval-rmse:0.881266\n","[1400]\ttrain-rmse:0.857904\tval-rmse:0.864366\n","[1600]\ttrain-rmse:0.85058\tval-rmse:0.85795\n","[1800]\ttrain-rmse:0.846647\tval-rmse:0.854929\n","[2000]\ttrain-rmse:0.843979\tval-rmse:0.853187\n","[2200]\ttrain-rmse:0.841814\tval-rmse:0.851929\n","[2400]\ttrain-rmse:0.839899\tval-rmse:0.850924\n","[2600]\ttrain-rmse:0.838202\tval-rmse:0.850107\n","[2800]\ttrain-rmse:0.836677\tval-rmse:0.849434\n","[3000]\ttrain-rmse:0.835215\tval-rmse:0.848862\n","[3200]\ttrain-rmse:0.833859\tval-rmse:0.84838\n","[3400]\ttrain-rmse:0.832589\tval-rmse:0.847943\n","[3600]\ttrain-rmse:0.831351\tval-rmse:0.847544\n","[3800]\ttrain-rmse:0.830253\tval-rmse:0.84723\n","[4000]\ttrain-rmse:0.829177\tval-rmse:0.846947\n","[4200]\ttrain-rmse:0.82813\tval-rmse:0.846695\n","[4400]\ttrain-rmse:0.82717\tval-rmse:0.846472\n","[4600]\ttrain-rmse:0.826246\tval-rmse:0.846288\n","[4800]\ttrain-rmse:0.825348\tval-rmse:0.846121\n","[5000]\ttrain-rmse:0.824497\tval-rmse:0.845973\n","[5200]\ttrain-rmse:0.823691\tval-rmse:0.845835\n","[5400]\ttrain-rmse:0.822939\tval-rmse:0.845746\n","[5600]\ttrain-rmse:0.822201\tval-rmse:0.845678\n","[5800]\ttrain-rmse:0.821499\tval-rmse:0.845605\n","[6000]\ttrain-rmse:0.820825\tval-rmse:0.845547\n","[6200]\ttrain-rmse:0.820183\tval-rmse:0.845487\n","[6400]\ttrain-rmse:0.819577\tval-rmse:0.845428\n","[6600]\ttrain-rmse:0.819014\tval-rmse:0.845378\n","[6800]\ttrain-rmse:0.818415\tval-rmse:0.845341\n","[7000]\ttrain-rmse:0.81784\tval-rmse:0.845309\n","[7200]\ttrain-rmse:0.817299\tval-rmse:0.845295\n","[7400]\ttrain-rmse:0.816764\tval-rmse:0.845261\n","[7600]\ttrain-rmse:0.816264\tval-rmse:0.845241\n","[7800]\ttrain-rmse:0.815778\tval-rmse:0.845206\n","[8000]\ttrain-rmse:0.81528\tval-rmse:0.845187\n","[8200]\ttrain-rmse:0.814825\tval-rmse:0.845166\n","[8400]\ttrain-rmse:0.814357\tval-rmse:0.845159\n","Stopping. Best iteration:\n","[8362]\ttrain-rmse:0.814449\tval-rmse:0.845159\n","\n","Model training1759.130[s]\n","Get Feature Importance8.544[s]\n","score: 0.84516\n","Predict Valid273.780[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 1\n","[0]\ttrain-rmse:6.99205\tval-rmse:6.99066\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90363\tval-rmse:3.90193\n","[400]\ttrain-rmse:2.26133\tval-rmse:2.25931\n","[600]\ttrain-rmse:1.43633\tval-rmse:1.43408\n","[800]\ttrain-rmse:1.06771\tval-rmse:1.06565\n","[1000]\ttrain-rmse:0.926036\tval-rmse:0.924598\n","[1200]\ttrain-rmse:0.876377\tval-rmse:0.875871\n","[1400]\ttrain-rmse:0.858569\tval-rmse:0.858989\n","[1600]\ttrain-rmse:0.851242\tval-rmse:0.85251\n","[1800]\ttrain-rmse:0.847307\tval-rmse:0.849458\n","[2000]\ttrain-rmse:0.844653\tval-rmse:0.847669\n","[2200]\ttrain-rmse:0.842496\tval-rmse:0.846322\n","[2400]\ttrain-rmse:0.840593\tval-rmse:0.845226\n","[2600]\ttrain-rmse:0.838906\tval-rmse:0.844351\n","[2800]\ttrain-rmse:0.837373\tval-rmse:0.843615\n","[3000]\ttrain-rmse:0.835907\tval-rmse:0.842979\n","[3200]\ttrain-rmse:0.834563\tval-rmse:0.842435\n","[3400]\ttrain-rmse:0.833296\tval-rmse:0.841951\n","[3600]\ttrain-rmse:0.832046\tval-rmse:0.841536\n","[3800]\ttrain-rmse:0.830975\tval-rmse:0.84119\n","[4000]\ttrain-rmse:0.829884\tval-rmse:0.840893\n","[4200]\ttrain-rmse:0.828874\tval-rmse:0.840617\n","[4400]\ttrain-rmse:0.82792\tval-rmse:0.840389\n","[4600]\ttrain-rmse:0.82701\tval-rmse:0.840169\n","[4800]\ttrain-rmse:0.826155\tval-rmse:0.839998\n","[5000]\ttrain-rmse:0.825313\tval-rmse:0.839824\n","[5200]\ttrain-rmse:0.824516\tval-rmse:0.839686\n","[5400]\ttrain-rmse:0.823758\tval-rmse:0.839565\n","[5600]\ttrain-rmse:0.823021\tval-rmse:0.839455\n","[5800]\ttrain-rmse:0.822312\tval-rmse:0.839362\n","[6000]\ttrain-rmse:0.821654\tval-rmse:0.839294\n","[6200]\ttrain-rmse:0.821021\tval-rmse:0.839221\n","[6400]\ttrain-rmse:0.82041\tval-rmse:0.839172\n","[6600]\ttrain-rmse:0.819805\tval-rmse:0.839109\n","[6800]\ttrain-rmse:0.819223\tval-rmse:0.839056\n","[7000]\ttrain-rmse:0.818671\tval-rmse:0.839009\n","[7200]\ttrain-rmse:0.818166\tval-rmse:0.838972\n","[7400]\ttrain-rmse:0.817611\tval-rmse:0.838934\n","[7600]\ttrain-rmse:0.817101\tval-rmse:0.838901\n","[7800]\ttrain-rmse:0.816624\tval-rmse:0.838883\n","[8000]\ttrain-rmse:0.816124\tval-rmse:0.838866\n","[8200]\ttrain-rmse:0.815654\tval-rmse:0.838837\n","[8400]\ttrain-rmse:0.815206\tval-rmse:0.83882\n","[8600]\ttrain-rmse:0.814761\tval-rmse:0.838808\n","[8800]\ttrain-rmse:0.81431\tval-rmse:0.838795\n","[9000]\ttrain-rmse:0.813861\tval-rmse:0.838775\n","[9200]\ttrain-rmse:0.813454\tval-rmse:0.838762\n","[9400]\ttrain-rmse:0.813062\tval-rmse:0.838748\n","[9600]\ttrain-rmse:0.812644\tval-rmse:0.838745\n","Stopping. Best iteration:\n","[9522]\ttrain-rmse:0.81281\tval-rmse:0.838741\n","\n","Model training1998.160[s]\n","Get Feature Importance9.373[s]\n","score: 0.83874\n","Predict Valid318.191[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 2\n","[0]\ttrain-rmse:6.99381\tval-rmse:6.97476\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90448\tval-rmse:3.88605\n","[400]\ttrain-rmse:2.26163\tval-rmse:2.24474\n","[600]\ttrain-rmse:1.43628\tval-rmse:1.4227\n","[800]\ttrain-rmse:1.06737\tval-rmse:1.05894\n","[1000]\ttrain-rmse:0.925516\tval-rmse:0.922371\n","[1200]\ttrain-rmse:0.875812\tval-rmse:0.876759\n","[1400]\ttrain-rmse:0.857958\tval-rmse:0.861756\n","[1600]\ttrain-rmse:0.850626\tval-rmse:0.856416\n","[1800]\ttrain-rmse:0.846705\tval-rmse:0.854081\n","[2000]\ttrain-rmse:0.844021\tval-rmse:0.852681\n","[2200]\ttrain-rmse:0.841871\tval-rmse:0.851603\n","[2400]\ttrain-rmse:0.839955\tval-rmse:0.850729\n","[2600]\ttrain-rmse:0.838273\tval-rmse:0.849992\n","[2800]\ttrain-rmse:0.83672\tval-rmse:0.849391\n","[3000]\ttrain-rmse:0.835252\tval-rmse:0.84886\n","[3200]\ttrain-rmse:0.833874\tval-rmse:0.848378\n","[3400]\ttrain-rmse:0.832598\tval-rmse:0.847964\n","[3600]\ttrain-rmse:0.831352\tval-rmse:0.847583\n","[3800]\ttrain-rmse:0.830257\tval-rmse:0.847291\n","[4000]\ttrain-rmse:0.829154\tval-rmse:0.847018\n","[4200]\ttrain-rmse:0.828133\tval-rmse:0.846757\n","[4400]\ttrain-rmse:0.827185\tval-rmse:0.846565\n","[4600]\ttrain-rmse:0.826268\tval-rmse:0.84638\n","[4800]\ttrain-rmse:0.825382\tval-rmse:0.846222\n","[5000]\ttrain-rmse:0.824528\tval-rmse:0.84607\n","[5200]\ttrain-rmse:0.823741\tval-rmse:0.845972\n","[5400]\ttrain-rmse:0.822992\tval-rmse:0.845876\n","[5600]\ttrain-rmse:0.822288\tval-rmse:0.8458\n","[5800]\ttrain-rmse:0.821595\tval-rmse:0.845725\n","[6000]\ttrain-rmse:0.820921\tval-rmse:0.845663\n","[6200]\ttrain-rmse:0.8203\tval-rmse:0.8456\n","[6400]\ttrain-rmse:0.81968\tval-rmse:0.845549\n","[6600]\ttrain-rmse:0.819122\tval-rmse:0.845503\n","[6800]\ttrain-rmse:0.818526\tval-rmse:0.845452\n","[7000]\ttrain-rmse:0.817949\tval-rmse:0.845418\n","[7200]\ttrain-rmse:0.817403\tval-rmse:0.84539\n","[7400]\ttrain-rmse:0.816846\tval-rmse:0.845363\n","[7600]\ttrain-rmse:0.816344\tval-rmse:0.845348\n","[7800]\ttrain-rmse:0.815877\tval-rmse:0.845331\n","[8000]\ttrain-rmse:0.815394\tval-rmse:0.845317\n","[8200]\ttrain-rmse:0.81495\tval-rmse:0.845315\n","[8400]\ttrain-rmse:0.814472\tval-rmse:0.845299\n","[8600]\ttrain-rmse:0.814037\tval-rmse:0.845285\n","[8800]\ttrain-rmse:0.813617\tval-rmse:0.845278\n","[9000]\ttrain-rmse:0.813165\tval-rmse:0.845272\n","Stopping. Best iteration:\n","[8893]\ttrain-rmse:0.813409\tval-rmse:0.84527\n","\n","Model training1873.659[s]\n","Get Feature Importance8.873[s]\n","score: 0.84527\n","Predict Valid290.562[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 3\n","[0]\ttrain-rmse:6.99108\tval-rmse:6.99931\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90311\tval-rmse:3.91122\n","[400]\ttrain-rmse:2.26098\tval-rmse:2.26875\n","[600]\ttrain-rmse:1.43606\tval-rmse:1.44294\n","[800]\ttrain-rmse:1.06746\tval-rmse:1.07297\n","[1000]\ttrain-rmse:0.925721\tval-rmse:0.930132\n","[1200]\ttrain-rmse:0.875996\tval-rmse:0.880038\n","[1400]\ttrain-rmse:0.858168\tval-rmse:0.862436\n","[1600]\ttrain-rmse:0.850805\tval-rmse:0.855633\n","[1800]\ttrain-rmse:0.846854\tval-rmse:0.852459\n","[2000]\ttrain-rmse:0.844178\tval-rmse:0.850659\n","[2200]\ttrain-rmse:0.842013\tval-rmse:0.849387\n","[2400]\ttrain-rmse:0.840123\tval-rmse:0.848437\n","[2600]\ttrain-rmse:0.838435\tval-rmse:0.847676\n","[2800]\ttrain-rmse:0.836884\tval-rmse:0.847024\n","[3000]\ttrain-rmse:0.835434\tval-rmse:0.846486\n","[3200]\ttrain-rmse:0.834072\tval-rmse:0.846029\n","[3400]\ttrain-rmse:0.832796\tval-rmse:0.845636\n","[3600]\ttrain-rmse:0.831541\tval-rmse:0.845272\n","[3800]\ttrain-rmse:0.830442\tval-rmse:0.844978\n","[4000]\ttrain-rmse:0.829363\tval-rmse:0.844724\n","[4200]\ttrain-rmse:0.828339\tval-rmse:0.8445\n","[4400]\ttrain-rmse:0.827373\tval-rmse:0.844305\n","[4600]\ttrain-rmse:0.826448\tval-rmse:0.84413\n","[4800]\ttrain-rmse:0.825579\tval-rmse:0.843986\n","[5000]\ttrain-rmse:0.824725\tval-rmse:0.843853\n","[5200]\ttrain-rmse:0.823936\tval-rmse:0.843751\n","[5400]\ttrain-rmse:0.823165\tval-rmse:0.843664\n","[5600]\ttrain-rmse:0.822429\tval-rmse:0.843573\n","[5800]\ttrain-rmse:0.821749\tval-rmse:0.84349\n","[6000]\ttrain-rmse:0.821119\tval-rmse:0.84342\n","[6200]\ttrain-rmse:0.820439\tval-rmse:0.843364\n","[6400]\ttrain-rmse:0.819826\tval-rmse:0.843305\n","[6600]\ttrain-rmse:0.819229\tval-rmse:0.843255\n","[6800]\ttrain-rmse:0.818653\tval-rmse:0.843208\n","[7000]\ttrain-rmse:0.818095\tval-rmse:0.843168\n","[7200]\ttrain-rmse:0.817606\tval-rmse:0.843146\n","[7400]\ttrain-rmse:0.81704\tval-rmse:0.84311\n","[7600]\ttrain-rmse:0.816518\tval-rmse:0.84307\n","[7800]\ttrain-rmse:0.816041\tval-rmse:0.84305\n","[8000]\ttrain-rmse:0.815546\tval-rmse:0.843015\n","[8200]\ttrain-rmse:0.815094\tval-rmse:0.842998\n","[8400]\ttrain-rmse:0.814633\tval-rmse:0.842969\n","[8600]\ttrain-rmse:0.814194\tval-rmse:0.842956\n","[8800]\ttrain-rmse:0.813754\tval-rmse:0.842934\n","[9000]\ttrain-rmse:0.813325\tval-rmse:0.842923\n","[9200]\ttrain-rmse:0.812915\tval-rmse:0.842921\n","[9400]\ttrain-rmse:0.812515\tval-rmse:0.842912\n","[9600]\ttrain-rmse:0.812094\tval-rmse:0.842904\n","[9800]\ttrain-rmse:0.811677\tval-rmse:0.842894\n","[10000]\ttrain-rmse:0.811277\tval-rmse:0.842891\n","[10200]\ttrain-rmse:0.810883\tval-rmse:0.84289\n","Stopping. Best iteration:\n","[10076]\ttrain-rmse:0.811122\tval-rmse:0.842884\n","\n","Model training2098.393[s]\n","Get Feature Importance9.917[s]\n","score: 0.84289\n","Predict Valid420.469[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 4\n","[0]\ttrain-rmse:6.99169\tval-rmse:6.99389\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90342\tval-rmse:3.90555\n","[400]\ttrain-rmse:2.26116\tval-rmse:2.26315\n","[600]\ttrain-rmse:1.43619\tval-rmse:1.43789\n","[800]\ttrain-rmse:1.06755\tval-rmse:1.06899\n","[1000]\ttrain-rmse:0.925801\tval-rmse:0.927309\n","[1200]\ttrain-rmse:0.876129\tval-rmse:0.878104\n","[1400]\ttrain-rmse:0.858288\tval-rmse:0.860975\n","[1600]\ttrain-rmse:0.850964\tval-rmse:0.854419\n","[1800]\ttrain-rmse:0.847034\tval-rmse:0.851384\n","[2000]\ttrain-rmse:0.844369\tval-rmse:0.849616\n","[2200]\ttrain-rmse:0.842224\tval-rmse:0.848333\n","[2400]\ttrain-rmse:0.840315\tval-rmse:0.847317\n","[2600]\ttrain-rmse:0.838631\tval-rmse:0.846512\n","[2800]\ttrain-rmse:0.837092\tval-rmse:0.845831\n","[3000]\ttrain-rmse:0.835623\tval-rmse:0.845245\n","[3200]\ttrain-rmse:0.834288\tval-rmse:0.844753\n","[3400]\ttrain-rmse:0.833027\tval-rmse:0.844303\n","[3600]\ttrain-rmse:0.831782\tval-rmse:0.84391\n","[3800]\ttrain-rmse:0.830701\tval-rmse:0.843571\n","[4000]\ttrain-rmse:0.829645\tval-rmse:0.84327\n","[4200]\ttrain-rmse:0.828641\tval-rmse:0.843\n","[4400]\ttrain-rmse:0.827691\tval-rmse:0.842774\n","[4600]\ttrain-rmse:0.826759\tval-rmse:0.842575\n","[4800]\ttrain-rmse:0.825884\tval-rmse:0.842385\n","[5000]\ttrain-rmse:0.82501\tval-rmse:0.842225\n","[5200]\ttrain-rmse:0.824207\tval-rmse:0.842093\n","[5400]\ttrain-rmse:0.823439\tval-rmse:0.84197\n","[5600]\ttrain-rmse:0.822736\tval-rmse:0.84187\n","[5800]\ttrain-rmse:0.822043\tval-rmse:0.841767\n","[6000]\ttrain-rmse:0.821368\tval-rmse:0.84169\n","[6200]\ttrain-rmse:0.820749\tval-rmse:0.841614\n","[6400]\ttrain-rmse:0.820124\tval-rmse:0.841528\n","[6600]\ttrain-rmse:0.819548\tval-rmse:0.841466\n","[6800]\ttrain-rmse:0.818939\tval-rmse:0.841412\n","[7000]\ttrain-rmse:0.818406\tval-rmse:0.84137\n","[7200]\ttrain-rmse:0.817883\tval-rmse:0.84133\n","[7400]\ttrain-rmse:0.817324\tval-rmse:0.841286\n","[7600]\ttrain-rmse:0.816794\tval-rmse:0.841249\n","[7800]\ttrain-rmse:0.816308\tval-rmse:0.841219\n","[8000]\ttrain-rmse:0.81582\tval-rmse:0.841186\n","[8200]\ttrain-rmse:0.81537\tval-rmse:0.841167\n","[8400]\ttrain-rmse:0.814895\tval-rmse:0.841146\n","[8600]\ttrain-rmse:0.814462\tval-rmse:0.841131\n","[8800]\ttrain-rmse:0.814025\tval-rmse:0.841098\n","[9000]\ttrain-rmse:0.813611\tval-rmse:0.841077\n","[9200]\ttrain-rmse:0.813217\tval-rmse:0.841054\n","[9400]\ttrain-rmse:0.812796\tval-rmse:0.841055\n","Stopping. Best iteration:\n","[9247]\ttrain-rmse:0.813111\tval-rmse:0.841046\n","\n","Model training1940.173[s]\n","Get Feature Importance9.177[s]\n","score: 0.84105\n","Predict Valid324.497[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 5\n","[0]\ttrain-rmse:6.99231\tval-rmse:6.98828\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90369\tval-rmse:3.89993\n","[400]\ttrain-rmse:2.26123\tval-rmse:2.25813\n","[600]\ttrain-rmse:1.43606\tval-rmse:1.4343\n","[800]\ttrain-rmse:1.06724\tval-rmse:1.0674\n","[1000]\ttrain-rmse:0.925453\tval-rmse:0.927613\n","[1200]\ttrain-rmse:0.875749\tval-rmse:0.879652\n","[1400]\ttrain-rmse:0.857914\tval-rmse:0.863213\n","[1600]\ttrain-rmse:0.850575\tval-rmse:0.857045\n","[1800]\ttrain-rmse:0.846648\tval-rmse:0.854159\n","[2000]\ttrain-rmse:0.843997\tval-rmse:0.852489\n","[2200]\ttrain-rmse:0.84185\tval-rmse:0.851253\n","[2400]\ttrain-rmse:0.83996\tval-rmse:0.850271\n","[2600]\ttrain-rmse:0.838259\tval-rmse:0.849427\n","[2800]\ttrain-rmse:0.836711\tval-rmse:0.848736\n","[3000]\ttrain-rmse:0.835231\tval-rmse:0.848138\n","[3200]\ttrain-rmse:0.833874\tval-rmse:0.847627\n","[3400]\ttrain-rmse:0.832592\tval-rmse:0.84719\n","[3600]\ttrain-rmse:0.831374\tval-rmse:0.846808\n","[3800]\ttrain-rmse:0.830273\tval-rmse:0.846502\n","[4000]\ttrain-rmse:0.829202\tval-rmse:0.846198\n","[4200]\ttrain-rmse:0.828174\tval-rmse:0.845923\n","[4400]\ttrain-rmse:0.827243\tval-rmse:0.845704\n","[4600]\ttrain-rmse:0.826313\tval-rmse:0.845512\n","[4800]\ttrain-rmse:0.825446\tval-rmse:0.845327\n","[5000]\ttrain-rmse:0.824569\tval-rmse:0.845163\n","[5200]\ttrain-rmse:0.82378\tval-rmse:0.845032\n","[5400]\ttrain-rmse:0.823026\tval-rmse:0.844925\n","[5600]\ttrain-rmse:0.822302\tval-rmse:0.844822\n","[5800]\ttrain-rmse:0.821613\tval-rmse:0.844732\n","[6000]\ttrain-rmse:0.820961\tval-rmse:0.84464\n","[6200]\ttrain-rmse:0.820302\tval-rmse:0.844563\n","[6400]\ttrain-rmse:0.819716\tval-rmse:0.8445\n","[6600]\ttrain-rmse:0.819129\tval-rmse:0.844447\n","[6800]\ttrain-rmse:0.818551\tval-rmse:0.844394\n","[7000]\ttrain-rmse:0.818018\tval-rmse:0.844352\n","[7200]\ttrain-rmse:0.81748\tval-rmse:0.844316\n","[7400]\ttrain-rmse:0.81693\tval-rmse:0.844268\n","[7600]\ttrain-rmse:0.816409\tval-rmse:0.844238\n","[7800]\ttrain-rmse:0.815926\tval-rmse:0.844201\n","[8000]\ttrain-rmse:0.815455\tval-rmse:0.844169\n","[8200]\ttrain-rmse:0.815016\tval-rmse:0.844135\n","[8400]\ttrain-rmse:0.814566\tval-rmse:0.844104\n","[8600]\ttrain-rmse:0.814133\tval-rmse:0.844089\n","[8800]\ttrain-rmse:0.813685\tval-rmse:0.844082\n","[9000]\ttrain-rmse:0.813259\tval-rmse:0.84407\n","[9200]\ttrain-rmse:0.81287\tval-rmse:0.844064\n","[9400]\ttrain-rmse:0.812477\tval-rmse:0.844062\n","[9600]\ttrain-rmse:0.812065\tval-rmse:0.844053\n","[9800]\ttrain-rmse:0.811643\tval-rmse:0.844041\n","[10000]\ttrain-rmse:0.811249\tval-rmse:0.844036\n","Stopping. Best iteration:\n","[9911]\ttrain-rmse:0.811417\tval-rmse:0.844033\n","\n","Model training2062.908[s]\n","Get Feature Importance9.611[s]\n","score: 0.84403\n","Predict Valid343.151[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 6\n","[0]\ttrain-rmse:6.99212\tval-rmse:6.99003\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90367\tval-rmse:3.90153\n","[400]\ttrain-rmse:2.2614\tval-rmse:2.25925\n","[600]\ttrain-rmse:1.43638\tval-rmse:1.43434\n","[800]\ttrain-rmse:1.06764\tval-rmse:1.06611\n","[1000]\ttrain-rmse:0.925853\tval-rmse:0.925233\n","[1200]\ttrain-rmse:0.876122\tval-rmse:0.876649\n","[1400]\ttrain-rmse:0.858266\tval-rmse:0.859963\n","[1600]\ttrain-rmse:0.850929\tval-rmse:0.853719\n","[1800]\ttrain-rmse:0.846988\tval-rmse:0.850893\n","[2000]\ttrain-rmse:0.844309\tval-rmse:0.849279\n","[2200]\ttrain-rmse:0.842142\tval-rmse:0.848092\n","[2400]\ttrain-rmse:0.840238\tval-rmse:0.847167\n","[2600]\ttrain-rmse:0.838552\tval-rmse:0.846423\n","[2800]\ttrain-rmse:0.837\tval-rmse:0.845803\n","[3000]\ttrain-rmse:0.83554\tval-rmse:0.845258\n","[3200]\ttrain-rmse:0.834185\tval-rmse:0.844814\n","[3400]\ttrain-rmse:0.832929\tval-rmse:0.844401\n","[3600]\ttrain-rmse:0.831696\tval-rmse:0.844053\n","[3800]\ttrain-rmse:0.830597\tval-rmse:0.843764\n","[4000]\ttrain-rmse:0.829525\tval-rmse:0.843514\n","[4200]\ttrain-rmse:0.828473\tval-rmse:0.843269\n","[4400]\ttrain-rmse:0.827513\tval-rmse:0.843082\n","[4600]\ttrain-rmse:0.826595\tval-rmse:0.842907\n","[4800]\ttrain-rmse:0.825692\tval-rmse:0.842743\n","[5000]\ttrain-rmse:0.824822\tval-rmse:0.842593\n","[5200]\ttrain-rmse:0.824017\tval-rmse:0.842472\n","[5400]\ttrain-rmse:0.823294\tval-rmse:0.842383\n","[5600]\ttrain-rmse:0.82256\tval-rmse:0.842292\n","[5800]\ttrain-rmse:0.821872\tval-rmse:0.842226\n","[6000]\ttrain-rmse:0.821222\tval-rmse:0.842158\n","[6200]\ttrain-rmse:0.820577\tval-rmse:0.842107\n","[6400]\ttrain-rmse:0.819954\tval-rmse:0.842051\n","[6600]\ttrain-rmse:0.819377\tval-rmse:0.842012\n","[6800]\ttrain-rmse:0.81877\tval-rmse:0.84196\n","[7000]\ttrain-rmse:0.818245\tval-rmse:0.841931\n","[7200]\ttrain-rmse:0.817713\tval-rmse:0.841916\n","[7400]\ttrain-rmse:0.817162\tval-rmse:0.841881\n","[7600]\ttrain-rmse:0.816644\tval-rmse:0.841862\n","[7800]\ttrain-rmse:0.816169\tval-rmse:0.841833\n","[8000]\ttrain-rmse:0.815686\tval-rmse:0.841813\n","[8200]\ttrain-rmse:0.81523\tval-rmse:0.841793\n","[8400]\ttrain-rmse:0.814761\tval-rmse:0.841781\n","[8600]\ttrain-rmse:0.814316\tval-rmse:0.841773\n","[8800]\ttrain-rmse:0.81389\tval-rmse:0.841764\n","[9000]\ttrain-rmse:0.813449\tval-rmse:0.841755\n","[9200]\ttrain-rmse:0.813013\tval-rmse:0.841744\n","[9400]\ttrain-rmse:0.812589\tval-rmse:0.841735\n","[9600]\ttrain-rmse:0.812156\tval-rmse:0.841731\n","Stopping. Best iteration:\n","[9462]\ttrain-rmse:0.812452\tval-rmse:0.84173\n","\n","Model training1975.884[s]\n","Get Feature Importance9.359[s]\n","score: 0.84173\n","Predict Valid328.262[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 7\n","[0]\ttrain-rmse:6.99183\tval-rmse:6.99261\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90346\tval-rmse:3.90444\n","[400]\ttrain-rmse:2.2612\tval-rmse:2.26232\n","[600]\ttrain-rmse:1.43618\tval-rmse:1.43742\n","[800]\ttrain-rmse:1.06753\tval-rmse:1.06887\n","[1000]\ttrain-rmse:0.925811\tval-rmse:0.927395\n","[1200]\ttrain-rmse:0.87613\tval-rmse:0.878269\n","[1400]\ttrain-rmse:0.858334\tval-rmse:0.861168\n","[1600]\ttrain-rmse:0.85098\tval-rmse:0.85457\n","[1800]\ttrain-rmse:0.847039\tval-rmse:0.851509\n","[2000]\ttrain-rmse:0.844362\tval-rmse:0.849738\n","[2200]\ttrain-rmse:0.842198\tval-rmse:0.848467\n","[2400]\ttrain-rmse:0.840295\tval-rmse:0.847436\n","[2600]\ttrain-rmse:0.838619\tval-rmse:0.84662\n","[2800]\ttrain-rmse:0.83709\tval-rmse:0.845932\n","[3000]\ttrain-rmse:0.835637\tval-rmse:0.845352\n","[3200]\ttrain-rmse:0.83428\tval-rmse:0.844882\n","[3400]\ttrain-rmse:0.832998\tval-rmse:0.844439\n","[3600]\ttrain-rmse:0.831752\tval-rmse:0.844081\n","[3800]\ttrain-rmse:0.830638\tval-rmse:0.843768\n","[4000]\ttrain-rmse:0.829571\tval-rmse:0.843479\n","[4200]\ttrain-rmse:0.828542\tval-rmse:0.843208\n","[4400]\ttrain-rmse:0.827591\tval-rmse:0.843007\n","[4600]\ttrain-rmse:0.826664\tval-rmse:0.84283\n","[4800]\ttrain-rmse:0.825773\tval-rmse:0.842653\n","[5000]\ttrain-rmse:0.824909\tval-rmse:0.842513\n","[5200]\ttrain-rmse:0.824103\tval-rmse:0.842401\n","[5400]\ttrain-rmse:0.823363\tval-rmse:0.842292\n","[5600]\ttrain-rmse:0.822636\tval-rmse:0.842197\n","[5800]\ttrain-rmse:0.821952\tval-rmse:0.842126\n","[6000]\ttrain-rmse:0.821278\tval-rmse:0.842068\n","[6200]\ttrain-rmse:0.820594\tval-rmse:0.842009\n","[6400]\ttrain-rmse:0.819952\tval-rmse:0.841954\n","[6600]\ttrain-rmse:0.819381\tval-rmse:0.841916\n","[6800]\ttrain-rmse:0.818764\tval-rmse:0.841873\n","[7000]\ttrain-rmse:0.818217\tval-rmse:0.841838\n","[7200]\ttrain-rmse:0.817686\tval-rmse:0.841808\n","[7400]\ttrain-rmse:0.817146\tval-rmse:0.841769\n","[7600]\ttrain-rmse:0.816649\tval-rmse:0.841748\n","[7800]\ttrain-rmse:0.816176\tval-rmse:0.841712\n","[8000]\ttrain-rmse:0.815673\tval-rmse:0.841699\n","[8200]\ttrain-rmse:0.815223\tval-rmse:0.841679\n","[8400]\ttrain-rmse:0.814758\tval-rmse:0.841666\n","[8600]\ttrain-rmse:0.81431\tval-rmse:0.841656\n","[8800]\ttrain-rmse:0.813877\tval-rmse:0.841643\n","[9000]\ttrain-rmse:0.813437\tval-rmse:0.841623\n","[9200]\ttrain-rmse:0.812995\tval-rmse:0.841618\n","Stopping. Best iteration:\n","[9181]\ttrain-rmse:0.813043\tval-rmse:0.841615\n","\n","Model training1900.440[s]\n","Get Feature Importance9.120[s]\n","score: 0.84162\n","Predict Valid285.246[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 8\n","[0]\ttrain-rmse:6.99081\tval-rmse:7.00184\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90288\tval-rmse:3.91393\n","[400]\ttrain-rmse:2.26081\tval-rmse:2.2717\n","[600]\ttrain-rmse:1.4359\tval-rmse:1.44608\n","[800]\ttrain-rmse:1.0673\tval-rmse:1.07598\n","[1000]\ttrain-rmse:0.925611\tval-rmse:0.932718\n","[1200]\ttrain-rmse:0.875955\tval-rmse:0.882231\n","[1400]\ttrain-rmse:0.858156\tval-rmse:0.86423\n","[1600]\ttrain-rmse:0.850844\tval-rmse:0.857114\n","[1800]\ttrain-rmse:0.846905\tval-rmse:0.85369\n","[2000]\ttrain-rmse:0.844242\tval-rmse:0.851679\n","[2200]\ttrain-rmse:0.842061\tval-rmse:0.850215\n","[2400]\ttrain-rmse:0.840149\tval-rmse:0.849087\n","[2600]\ttrain-rmse:0.838442\tval-rmse:0.848163\n","[2800]\ttrain-rmse:0.836905\tval-rmse:0.847406\n","[3000]\ttrain-rmse:0.835432\tval-rmse:0.846776\n","[3200]\ttrain-rmse:0.834077\tval-rmse:0.84623\n","[3400]\ttrain-rmse:0.832825\tval-rmse:0.845752\n","[3600]\ttrain-rmse:0.83159\tval-rmse:0.845328\n","[3800]\ttrain-rmse:0.830499\tval-rmse:0.84499\n","[4000]\ttrain-rmse:0.829408\tval-rmse:0.844697\n","[4200]\ttrain-rmse:0.828381\tval-rmse:0.844421\n","[4400]\ttrain-rmse:0.827426\tval-rmse:0.844182\n","[4600]\ttrain-rmse:0.826525\tval-rmse:0.843969\n","[4800]\ttrain-rmse:0.825641\tval-rmse:0.843786\n","[5000]\ttrain-rmse:0.824775\tval-rmse:0.843628\n","[5200]\ttrain-rmse:0.823981\tval-rmse:0.843494\n","[5400]\ttrain-rmse:0.823242\tval-rmse:0.843371\n","[5600]\ttrain-rmse:0.822536\tval-rmse:0.843249\n","[5800]\ttrain-rmse:0.821862\tval-rmse:0.843157\n","[6000]\ttrain-rmse:0.821215\tval-rmse:0.843064\n","[6200]\ttrain-rmse:0.820549\tval-rmse:0.84298\n","[6400]\ttrain-rmse:0.819925\tval-rmse:0.842907\n","[6600]\ttrain-rmse:0.819345\tval-rmse:0.842838\n","[6800]\ttrain-rmse:0.81876\tval-rmse:0.842776\n","[7000]\ttrain-rmse:0.818209\tval-rmse:0.842742\n","[7200]\ttrain-rmse:0.817704\tval-rmse:0.842696\n","[7400]\ttrain-rmse:0.817169\tval-rmse:0.842662\n","[7600]\ttrain-rmse:0.816651\tval-rmse:0.842622\n","[7800]\ttrain-rmse:0.816144\tval-rmse:0.84259\n","[8000]\ttrain-rmse:0.815618\tval-rmse:0.842561\n","[8200]\ttrain-rmse:0.815156\tval-rmse:0.842532\n","[8400]\ttrain-rmse:0.814672\tval-rmse:0.842507\n","[8600]\ttrain-rmse:0.814228\tval-rmse:0.842495\n","[8800]\ttrain-rmse:0.813781\tval-rmse:0.842477\n","[9000]\ttrain-rmse:0.813353\tval-rmse:0.842465\n","[9200]\ttrain-rmse:0.812935\tval-rmse:0.842456\n","[9400]\ttrain-rmse:0.812532\tval-rmse:0.842455\n","[9600]\ttrain-rmse:0.812122\tval-rmse:0.842435\n","[9800]\ttrain-rmse:0.811693\tval-rmse:0.842438\n","Stopping. Best iteration:\n","[9623]\ttrain-rmse:0.812072\tval-rmse:0.842428\n","\n","Model training1997.900[s]\n","Get Feature Importance9.423[s]\n","score: 0.84243\n","Predict Valid293.599[s]\n","****************************************************************************************************\n","Seed: 42 - Fold: 9\n","[0]\ttrain-rmse:6.99153\tval-rmse:6.99537\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[200]\ttrain-rmse:3.90342\tval-rmse:3.90652\n","[400]\ttrain-rmse:2.26134\tval-rmse:2.26331\n","[600]\ttrain-rmse:1.43647\tval-rmse:1.43693\n","[800]\ttrain-rmse:1.06788\tval-rmse:1.0669\n","[1000]\ttrain-rmse:0.926155\tval-rmse:0.92445\n","[1200]\ttrain-rmse:0.876471\tval-rmse:0.874921\n","[1400]\ttrain-rmse:0.858627\tval-rmse:0.857689\n","[1600]\ttrain-rmse:0.85127\tval-rmse:0.851147\n","[1800]\ttrain-rmse:0.847312\tval-rmse:0.848133\n","[2000]\ttrain-rmse:0.84463\tval-rmse:0.846413\n","[2200]\ttrain-rmse:0.842467\tval-rmse:0.845199\n","[2400]\ttrain-rmse:0.840563\tval-rmse:0.844266\n","[2600]\ttrain-rmse:0.838882\tval-rmse:0.843508\n","[2800]\ttrain-rmse:0.837332\tval-rmse:0.842884\n","[3000]\ttrain-rmse:0.835863\tval-rmse:0.842335\n","[3200]\ttrain-rmse:0.834488\tval-rmse:0.841875\n","[3400]\ttrain-rmse:0.833227\tval-rmse:0.841485\n","[3600]\ttrain-rmse:0.831991\tval-rmse:0.841157\n","[3800]\ttrain-rmse:0.830876\tval-rmse:0.840876\n","[4000]\ttrain-rmse:0.82978\tval-rmse:0.840625\n","[4200]\ttrain-rmse:0.828752\tval-rmse:0.840402\n","[4400]\ttrain-rmse:0.827804\tval-rmse:0.840205\n","[4600]\ttrain-rmse:0.826887\tval-rmse:0.840029\n","[4800]\ttrain-rmse:0.825986\tval-rmse:0.839883\n","[5000]\ttrain-rmse:0.825121\tval-rmse:0.839745\n","[5200]\ttrain-rmse:0.824322\tval-rmse:0.839617\n","[5400]\ttrain-rmse:0.823577\tval-rmse:0.839545\n","[5600]\ttrain-rmse:0.822837\tval-rmse:0.83947\n","[5800]\ttrain-rmse:0.822116\tval-rmse:0.839404\n","[6000]\ttrain-rmse:0.821446\tval-rmse:0.839336\n","[6200]\ttrain-rmse:0.820786\tval-rmse:0.839281\n","[6400]\ttrain-rmse:0.820166\tval-rmse:0.839234\n","[6600]\ttrain-rmse:0.819592\tval-rmse:0.839192\n","[6800]\ttrain-rmse:0.818996\tval-rmse:0.83916\n","[7000]\ttrain-rmse:0.818446\tval-rmse:0.839127\n","[7200]\ttrain-rmse:0.817911\tval-rmse:0.839102\n","[7400]\ttrain-rmse:0.817388\tval-rmse:0.839079\n","[7600]\ttrain-rmse:0.816882\tval-rmse:0.83906\n","[7800]\ttrain-rmse:0.816369\tval-rmse:0.839031\n","[8000]\ttrain-rmse:0.815874\tval-rmse:0.839023\n","[8200]\ttrain-rmse:0.81542\tval-rmse:0.839013\n","[8400]\ttrain-rmse:0.814964\tval-rmse:0.838997\n","[8600]\ttrain-rmse:0.814526\tval-rmse:0.838994\n","[8800]\ttrain-rmse:0.814108\tval-rmse:0.838987\n","Stopping. Best iteration:\n","[8704]\ttrain-rmse:0.814312\tval-rmse:0.838984\n","\n","Model training1837.052[s]\n","Get Feature Importance8.823[s]\n","score: 0.83898\n","Predict Valid310.810[s]\n","oof score:  0.842193\n"]}],"source":["oof_pred_xgb, test_pred_xgb, score_xgb, feat_imps_xgb = run_train_and_inference(\r\n","    X, X_test, y, \"xgb\", MODEL_PARAMS[\"xgb\"], TRAIN_PARAMS[\"xgb\"], RANDOM_SEED_LIST, N_SPLITS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42xQqvnji14e"},"outputs":[],"source":["submission.to_csv(\"new_bl_mine.csv\", index = True)\r\n","!cp new_bl_mine.csv \"drive/My Drive/\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPzGostVtSBFXsqnGR9O4Bo","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1dbtS_rhaUqs09O5lOhuc90c1Mun-M-z3","name":"TPS_Feb_3GBDT(0.84221).ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}